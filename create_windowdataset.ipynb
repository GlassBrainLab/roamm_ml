{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create window datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 632, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: '_control_lock'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 575, in _log_error\n",
      "    f.result()\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 301, in dispatch_control\n",
      "    async with self._control_lock:\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 687, in __get__\n",
      "    return t.cast(G, self.get(obj, cls))  # the G should encode the Optional\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 649, in get\n",
      "    value = self._validate(obj, default)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 722, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 2311, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/gpfs1/pi/djangraw/hsun11/miniconda3/envs/iclr26/lib/python3.12/site-packages/traitlets/traitlets.py\", line 831, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The '_control_lock' trait of an IPythonKernel instance expected a Lock, not the NoneType None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowed data and labels for subject s10014 have already been saved.\n",
      "Windowed data and labels for subject s10052 have already been saved.\n",
      "Windowed data and labels for subject s10059 have already been saved.\n",
      "Windowed data and labels for subject s10073 have already been saved.\n",
      "Windowed data and labels for subject s10081 have already been saved.\n",
      "Windowed data and labels for subject s10084 have already been saved.\n",
      "Windowed data and labels for subject s10085 have already been saved.\n",
      "Windowed data and labels for subject s10089 have already been saved.\n",
      "Windowed data and labels for subject s10094 have already been saved.\n",
      "Windowed data and labels for subject s10100 have already been saved.\n",
      "Windowed data and labels for subject s10103 have already been saved.\n",
      "Windowed data and labels for subject s10110 have already been saved.\n",
      "Windowed data and labels for subject s10111 have already been saved.\n",
      "Windowed data and labels for subject s10115 have already been saved.\n",
      "Windowed data and labels for subject s10117 have already been saved.\n",
      "Windowed data and labels for subject s10121 have already been saved.\n",
      "Windowed data and labels for subject s10125 have already been saved.\n",
      "Windowed data and labels for subject s10138 have already been saved.\n",
      "Windowed data and labels for subject s10139 have already been saved.\n",
      "Windowed data and labels for subject s10141 have already been saved.\n",
      "Windowed data and labels for subject s10144 have already been saved.\n",
      "Windowed data and labels for subject s10145 have already been saved.\n",
      "Windowed data and labels for subject s10148 have already been saved.\n",
      "Windowed data and labels for subject s10153 have already been saved.\n",
      "Windowed data and labels for subject s10156 have already been saved.\n",
      "Windowed data and labels for subject s10158 have already been saved.\n",
      "Windowed data and labels for subject s10159 have already been saved.\n",
      "Windowed data and labels for subject s10160 have already been saved.\n",
      "Windowed data and labels for subject s10165 have already been saved.\n",
      "Windowed data and labels for subject s10173 have already been saved.\n",
      "Windowed data and labels for subject s10177 have already been saved.\n",
      "Windowed data and labels for subject s10178 have already been saved.\n",
      "Windowed data and labels for subject s10180 have already been saved.\n",
      "Windowed data and labels for subject s10181 have already been saved.\n",
      "Windowed data and labels for subject s10183 have already been saved.\n",
      "Windowed data and labels for subject s10185 have already been saved.\n",
      "Windowed data and labels for subject s10186 have already been saved.\n",
      "Windowed data and labels for subject s10188 have already been saved.\n",
      "Windowed data and labels for subject s10192 have already been saved.\n",
      "Windowed data and labels for subject s10195 have already been saved.\n",
      "Windowed data and labels for subject s10196 have already been saved.\n",
      "Windowed data and labels for subject s10197 have already been saved.\n",
      "Windowed data and labels for subject s10200 have already been saved.\n",
      "Windowed data and labels for subject s10202 have already been saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define data root\n",
    "# this is the path to the ROAMM folder on local machine\n",
    "roamm_root = r\"/gpfs1/pi/djangraw/mindless_reading/ROAMM\"\n",
    "ml_data_root = os.path.join(roamm_root, 'subject_ml_data')\n",
    "random_seed = 42\n",
    "# define window size and sampling rate\n",
    "sfreq = 256\n",
    "window_seconds = 0.25\n",
    "\n",
    "all_subjects = sorted([d for d in os.listdir(ml_data_root) if d.startswith('s') and os.path.isdir(os.path.join(ml_data_root, d))])\n",
    "df = pd.DataFrame()\n",
    "for subject_id in all_subjects:\n",
    "    subject_dir = os.path.join(ml_data_root, subject_id)\n",
    "    save_dir = os.path.join(subject_dir, 'window_datasets')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if os.path.exists(save_dir) and len(os.listdir(save_dir)) == 3:\n",
    "        print(f'Windowed data and labels for subject {subject_id} have already been saved.')\n",
    "        continue\n",
    "    pkl_files = [f for f in os.listdir(subject_dir) if f.endswith('.pkl')]\n",
    "\n",
    "    # make sure each subject has 5 runs of data\n",
    "    if len(pkl_files) != 5:\n",
    "        raise ValueError(f\"Subject {subject_id} has {len(pkl_files)} runs instead of 5\")\n",
    "    \n",
    "    for pkl_file in pkl_files:\n",
    "        df_sub_single_run = pd.read_pickle(os.path.join(subject_dir, pkl_file))\n",
    "        df_sub_single_run = df_sub_single_run[df_sub_single_run['first_pass_reading'] == 1]\n",
    "        # convert bool col explicitly to avoid pandas warning\n",
    "        for col in ['is_blink', 'is_saccade', 'is_fixation', 'is_mw', 'first_pass_reading']:\n",
    "            df_sub_single_run[col] = df_sub_single_run[col] == True\n",
    "\n",
    "        # filter out samples 2 seconds before page end\n",
    "        mask = df_sub_single_run['time'] < df_sub_single_run['page_end']-2\n",
    "        df_sub_single_run = df_sub_single_run[mask]\n",
    "        # append to the dataframe\n",
    "        df = pd.concat([df, df_sub_single_run])\n",
    "        # add subject id to the dataframe\n",
    "        df['subject_id'] = subject_id\n",
    "    print(f'Subject {subject_id} has been loaded.')\n",
    "    \n",
    "    # normalize pupil size features\n",
    "    df['blink_interp_LPupil_norm'] = df['blink_interp_LPupil'] / df['blink_interp_LPupil'].median()\n",
    "    df['blink_interp_RPupil_norm'] = df['blink_interp_RPupil'] / df['blink_interp_RPupil'].median()\n",
    "\n",
    "    windowed_data = []\n",
    "    windowed_labels = []\n",
    "    window_size = int(sfreq * window_seconds)\n",
    "\n",
    "    # Process data in chunks of window_size\n",
    "    for i in range(0, len(df), window_size):\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        # Skip if window is too small\n",
    "        if len(window) < window_size:\n",
    "            continue\n",
    "        # Check if labels are consistent in this window\n",
    "        labels_in_window = window['is_mw'].unique()\n",
    "        if len(labels_in_window) > 1:\n",
    "            # Skip windows with mixed labels\n",
    "            continue\n",
    "\n",
    "        # Extract features for this window: keep as 2D array (window_size x feature_number)\n",
    "        windowed_data.append(window.values)\n",
    "        # Use the consistent label\n",
    "        windowed_labels.append(labels_in_window[0])\n",
    "\n",
    "    # Use RandomUnderSampler on flattened data, then recover 3D structure\n",
    "    windowed_data_flat = [w.flatten() for w in windowed_data]\n",
    "    undersampler = RandomUnderSampler(random_state=random_seed)\n",
    "    X_resampled_flat, y_resampled = undersampler.fit_resample(windowed_data_flat, windowed_labels)\n",
    "    # Recover 3D array: (n_samples, window_size, n_features)\n",
    "    window_size = windowed_data[0].shape[0]\n",
    "    n_features = windowed_data[0].shape[1]\n",
    "    X_resampled = np.array(X_resampled_flat).reshape(-1, window_size, n_features)\n",
    "    X = np.transpose(X_resampled, (0, 2, 1))  # (N, num_channels, window_size)\n",
    "    y = np.array(y_resampled, dtype=int)\n",
    "\n",
    "    # get col names\n",
    "    col_names = df.columns.tolist()\n",
    "\n",
    "    # save windowed data and labels\n",
    "    np.save(os.path.join(save_dir, f'{subject_id}_{window_size}windowed_data.npy'), X)\n",
    "    np.save(os.path.join(save_dir, f'{subject_id}_{window_size}windowed_labels.npy'), y)\n",
    "\n",
    "    # for col names, only save one copy\n",
    "    file_path = os.path.join(save_dir, f'{subject_id}_col_names.npy')\n",
    "    if not os.path.exists(file_path):\n",
    "        np.save(file_path, col_names)\n",
    "    \n",
    "    print(f'Windowed data and labels for subject {subject_id} have been saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iclr26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
