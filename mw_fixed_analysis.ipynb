{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83656321",
   "metadata": {},
   "source": [
    "# Generate mw_fixed eeg-et feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0bcd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing s10014\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10014/s10014_R_eeget_features_mw_fixed.csv\n",
      "Processing s10052\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10052/s10052_R_eeget_features_mw_fixed.csv\n",
      "Processing s10059\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10059/s10059_R_eeget_features_mw_fixed.csv\n",
      "Processing s10073\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10073/s10073_R_eeget_features_mw_fixed.csv\n",
      "Processing s10081\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10081/s10081_R_eeget_features_mw_fixed.csv\n",
      "Processing s10084\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10084/s10084_R_eeget_features_mw_fixed.csv\n",
      "Processing s10085\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10085/s10085_R_eeget_features_mw_fixed.csv\n",
      "Processing s10089\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10089/s10089_R_eeget_features_mw_fixed.csv\n",
      "Processing s10094\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10094/s10094_R_eeget_features_mw_fixed.csv\n",
      "Processing s10100\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10100/s10100_R_eeget_features_mw_fixed.csv\n",
      "Processing s10103\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10103/s10103_R_eeget_features_mw_fixed.csv\n",
      "Processing s10110\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10110/s10110_R_eeget_features_mw_fixed.csv\n",
      "Processing s10111\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10111/s10111_R_eeget_features_mw_fixed.csv\n",
      "Processing s10115\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10115/s10115_R_eeget_features_mw_fixed.csv\n",
      "Processing s10117\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10117/s10117_R_eeget_features_mw_fixed.csv\n",
      "Processing s10121\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10121/s10121_R_eeget_features_mw_fixed.csv\n",
      "Processing s10125\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10125/s10125_R_eeget_features_mw_fixed.csv\n",
      "Processing s10138\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10138/s10138_R_eeget_features_mw_fixed.csv\n",
      "Processing s10139\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10139/s10139_R_eeget_features_mw_fixed.csv\n",
      "Processing s10141\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10141/s10141_R_eeget_features_mw_fixed.csv\n",
      "Processing s10144\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10144/s10144_R_eeget_features_mw_fixed.csv\n",
      "Processing s10145\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10145/s10145_R_eeget_features_mw_fixed.csv\n",
      "Processing s10148\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10148/s10148_R_eeget_features_mw_fixed.csv\n",
      "Processing s10153\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10153/s10153_R_eeget_features_mw_fixed.csv\n",
      "Processing s10156\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10156/s10156_R_eeget_features_mw_fixed.csv\n",
      "Processing s10158\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10158/s10158_R_eeget_features_mw_fixed.csv\n",
      "Processing s10159\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10159/s10159_R_eeget_features_mw_fixed.csv\n",
      "Processing s10160\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10160/s10160_R_eeget_features_mw_fixed.csv\n",
      "Processing s10165\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10165/s10165_R_eeget_features_mw_fixed.csv\n",
      "Processing s10173\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10173/s10173_R_eeget_features_mw_fixed.csv\n",
      "Processing s10177\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10177/s10177_R_eeget_features_mw_fixed.csv\n",
      "Processing s10178\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10178/s10178_R_eeget_features_mw_fixed.csv\n",
      "Processing s10180\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10180/s10180_R_eeget_features_mw_fixed.csv\n",
      "Processing s10181\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10181/s10181_R_eeget_features_mw_fixed.csv\n",
      "Processing s10183\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10183/s10183_R_eeget_features_mw_fixed.csv\n",
      "Processing s10185\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10185/s10185_R_eeget_features_mw_fixed.csv\n",
      "Processing s10186\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10186/s10186_R_eeget_features_mw_fixed.csv\n",
      "Processing s10188\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10188/s10188_R_eeget_features_mw_fixed.csv\n",
      "Processing s10192\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10192/s10192_R_eeget_features_mw_fixed.csv\n",
      "Processing s10195\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10195/s10195_R_eeget_features_mw_fixed.csv\n",
      "Processing s10196\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10196/s10196_R_eeget_features_mw_fixed.csv\n",
      "Processing s10197\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10197/s10197_R_eeget_features_mw_fixed.csv\n",
      "Processing s10200\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10200/s10200_R_eeget_features_mw_fixed.csv\n",
      "Processing s10202\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/s10202/s10202_R_eeget_features_mw_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "# ==========================\n",
    "# EEG band definitions\n",
    "# ==========================\n",
    "band_names = [\n",
    "    \"theta1\", \"theta2\", \"alpha1\", \"alpha2\",\n",
    "    \"beta1\", \"beta2\", \"gamma1\", \"gamma2\",\n",
    "]\n",
    "\n",
    "band_defs = [\n",
    "    (4.0, 6.0),    # theta1\n",
    "    (6.5, 8.0),    # theta2\n",
    "    (8.5, 10.0),   # alpha1\n",
    "    (10.5, 13.0),  # alpha2\n",
    "    (13.5, 18.0),  # beta1\n",
    "    (18.5, 30.0),  # beta2\n",
    "    (30.5, 40.0),  # gamma1\n",
    "    (40.0, 49.5),  # gamma2\n",
    "]\n",
    "\n",
    "n_bands = len(band_defs)\n",
    "\n",
    "# ==========================\n",
    "# Paths\n",
    "# ==========================\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "\n",
    "all_subjects = sorted(\n",
    "    d for d in os.listdir(data_root)\n",
    "    if d.startswith(\"s\") and os.path.isdir(os.path.join(data_root, d))\n",
    ")\n",
    "\n",
    "col_name = None\n",
    "eeg_feature_names = None\n",
    "\n",
    "# ==========================\n",
    "# Main loop\n",
    "# ==========================\n",
    "for subject_id in all_subjects:\n",
    "    print(f\"Processing {subject_id}\")\n",
    "    subject_dir = os.path.join(data_root, subject_id)\n",
    "\n",
    "    # Page-level dataframe (where features go)\n",
    "    csv_path = os.path.join(subject_dir, f\"{subject_id}_R_features_mw_fixed_sr.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # drop rows with duration less than 2 seconds\n",
    "    df = df[df[\"win_dur\"] >= 2.0].reset_index(drop=True)\n",
    "\n",
    "    ml_dir = os.path.join(subject_dir, \"ml_data\")\n",
    "    pkl_files = sorted(f for f in os.listdir(ml_dir) if f.endswith(\".pkl\"))\n",
    "\n",
    "    for pkl_file in pkl_files:\n",
    "        df_run = pd.read_pickle(os.path.join(ml_dir, pkl_file))\n",
    "\n",
    "        # ==========================\n",
    "        # Channel & feature names (once)\n",
    "        # ==========================\n",
    "        if col_name is None:\n",
    "            col_name = df_run.columns[:64].tolist()\n",
    "\n",
    "            eeg_feature_names = [\n",
    "                f\"{ch}_{band}\"\n",
    "                for ch in col_name\n",
    "                for band in band_names\n",
    "            ]\n",
    "\n",
    "        # ==========================\n",
    "        # Run consistency check\n",
    "        # ==========================\n",
    "        run_nums = df_run[\"run_num\"].unique()\n",
    "        if run_nums.size != 1:\n",
    "            raise ValueError(f\"Multiple run numbers in {pkl_file}\")\n",
    "\n",
    "        run_num = run_nums[0]\n",
    "\n",
    "        # ==========================\n",
    "        # Page start alignment\n",
    "        # ==========================\n",
    "        page_start_time = df_run.loc[df_run[\"page_num\"] == 0, \"time\"].iloc[0]\n",
    "\n",
    "        df_page = df[df[\"run\"] == run_num]\n",
    "\n",
    "        win_start = (\n",
    "            df_page[\"win_start\"] - df_page[\"page_start\"]\n",
    "        ) + page_start_time\n",
    "\n",
    "        win_end = (\n",
    "            df_page[\"win_end\"] - df_page[\"page_start\"]\n",
    "        ) + page_start_time\n",
    "\n",
    "        # ==========================\n",
    "        # Window loop\n",
    "        # ==========================\n",
    "        for row_idx in df_page.index:\n",
    "            tstart = win_start.loc[row_idx]\n",
    "            tend = win_end.loc[row_idx]\n",
    "\n",
    "            eeg = (\n",
    "                df_run.loc[\n",
    "                    (df_run[\"time\"] >= tstart) &\n",
    "                    (df_run[\"time\"] <= tend),\n",
    "                    col_name\n",
    "                ]\n",
    "                .to_numpy()\n",
    "                .T\n",
    "            )  # shape: (64, n_times)\n",
    "\n",
    "            # ==========================\n",
    "            # PSD computation\n",
    "            # ==========================\n",
    "            psds, freqs = mne.time_frequency.psd_array_multitaper(\n",
    "                eeg,\n",
    "                sfreq=256,\n",
    "                fmin=4,\n",
    "                fmax=50,\n",
    "                output=\"power\",\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            # ==========================\n",
    "            # Band averaging\n",
    "            # ==========================\n",
    "            psds_band = np.zeros((64, n_bands), dtype=np.float32)\n",
    "\n",
    "            for band_i, (fmin, fmax) in enumerate(band_defs):\n",
    "                freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "                psds_band[:, band_i] = psds[:, freq_mask].mean(axis=1)\n",
    "\n",
    "            # ==========================\n",
    "            # Flattening (channel-major, band-minor)\n",
    "            # ==========================\n",
    "            df.loc[row_idx, eeg_feature_names] = psds_band.flatten()\n",
    "\n",
    "    # ==========================\n",
    "    # Save per subject\n",
    "    # ==========================\n",
    "    out_path = os.path.join(\n",
    "        subject_dir, f\"{subject_id}_R_eeget_features_mw_fixed.csv\"\n",
    "    )\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b1f61",
   "metadata": {},
   "source": [
    "## Combine individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10535045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for s10014\n",
      "Loading features for s10052\n",
      "Loading features for s10059\n",
      "Loading features for s10073\n",
      "Loading features for s10081\n",
      "Loading features for s10084\n",
      "Loading features for s10085\n",
      "Loading features for s10089\n",
      "Loading features for s10094\n",
      "Loading features for s10100\n",
      "Loading features for s10103\n",
      "Loading features for s10110\n",
      "Loading features for s10111\n",
      "Loading features for s10115\n",
      "Loading features for s10117\n",
      "Loading features for s10121\n",
      "Loading features for s10125\n",
      "Loading features for s10138\n",
      "Loading features for s10139\n",
      "Loading features for s10141\n",
      "Loading features for s10144\n",
      "Loading features for s10145\n",
      "Loading features for s10148\n",
      "Loading features for s10153\n",
      "Loading features for s10156\n",
      "Loading features for s10158\n",
      "Loading features for s10159\n",
      "Loading features for s10160\n",
      "Loading features for s10165\n",
      "Loading features for s10173\n",
      "Loading features for s10177\n",
      "Loading features for s10178\n",
      "Loading features for s10180\n",
      "Loading features for s10181\n",
      "Loading features for s10183\n",
      "Loading features for s10185\n",
      "Loading features for s10186\n",
      "Loading features for s10188\n",
      "Loading features for s10192\n",
      "Loading features for s10195\n",
      "Loading features for s10196\n",
      "Loading features for s10197\n",
      "Loading features for s10200\n",
      "Loading features for s10202\n",
      "Saved: /gpfs1/pi/djangraw/mindless_reading/data/all_subjects_R_eeget_features_mw_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================\n",
    "# Paths\n",
    "# ==========================\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "\n",
    "all_subjects = sorted(\n",
    "    d for d in os.listdir(data_root)\n",
    "    if d.startswith(\"s\") and os.path.isdir(os.path.join(data_root, d))\n",
    ")\n",
    "\n",
    "is_balance = True  # whether to balance classes by subsampling majority class\n",
    "\n",
    "df_list = []\n",
    "# ==========================\n",
    "# Main loop\n",
    "# ==========================\n",
    "for subject_id in all_subjects:\n",
    "    print(f\"Loading features for {subject_id}\")\n",
    "    subject_dir = os.path.join(data_root, subject_id)\n",
    "    csv_path = os.path.join(subject_dir, f\"{subject_id}_R_eeget_features_mw_fixed.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['label'] = df[\"is_MWreported\"].astype(int)\n",
    "    \n",
    "    if is_balance:\n",
    "        # Balance classes by subsampling majority class\n",
    "        class_counts = df[\"label\"].value_counts()\n",
    "        if len(class_counts) != 2:\n",
    "            print(f\"Warning: {subject_id} does not have exactly 2 classes. Skipping balancing.\")\n",
    "        else:\n",
    "            min_count = class_counts.min()\n",
    "            balanced_df = pd.concat([\n",
    "                df[df[\"label\"] == cls].sample(min_count, random_state=42)\n",
    "                for cls in class_counts.index\n",
    "            ])\n",
    "            df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    df[\"subject_id\"] = subject_id  # add subject_id column\n",
    "    df_list.append(df)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "out_path = os.path.join(data_root, \"all_subjects_R_eeget_features_mw_fixed.csv\")\n",
    "df_all.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ce030",
   "metadata": {},
   "source": [
    "# MW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a44cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(data_root, f\"all_subjects_R_eeget_features_mw_fixed.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fbc4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eye',\n",
       " 'fix_num',\n",
       " 'fix_word_num',\n",
       " 'norm_fix_word_num',\n",
       " 'norm_in_word_reg',\n",
       " 'norm_out_word_reg',\n",
       " 'zipf_fixdur_corr',\n",
       " 'word_length_fixdur_corr',\n",
       " 'norm_total_viewing',\n",
       " 'fix_dispersion',\n",
       " 'weighted_vergence',\n",
       " 'blink_num',\n",
       " 'blink_dur',\n",
       " 'blink_freq',\n",
       " 'ibi',\n",
       " 'ibi_baseline',\n",
       " 'sacc_num',\n",
       " 'norm_sacc_num',\n",
       " 'sacc_length',\n",
       " 'horizontal_sacc',\n",
       " 'pupil_baseline',\n",
       " 'pupil',\n",
       " 'pupil_mean',\n",
       " 'pupil_slope',\n",
       " 'page_norm_pupil',\n",
       " 'page_norm_pupil_mean',\n",
       " 'reading',\n",
       " 'run',\n",
       " 'page',\n",
       " 'page_start',\n",
       " 'page_end',\n",
       " 'win_start',\n",
       " 'win_end',\n",
       " 'win_dur',\n",
       " 'task_start',\n",
       " 'is_MWreported',\n",
       " 'is_MWvalid',\n",
       " 'mw_onset',\n",
       " 'mw_offset',\n",
       " 'Fp1_theta1',\n",
       " 'Fp1_theta2',\n",
       " 'Fp1_alpha1',\n",
       " 'Fp1_alpha2',\n",
       " 'Fp1_beta1',\n",
       " 'Fp1_beta2',\n",
       " 'Fp1_gamma1',\n",
       " 'Fp1_gamma2',\n",
       " 'AF7_theta1',\n",
       " 'AF7_theta2',\n",
       " 'AF7_alpha1',\n",
       " 'AF7_alpha2',\n",
       " 'AF7_beta1',\n",
       " 'AF7_beta2',\n",
       " 'AF7_gamma1',\n",
       " 'AF7_gamma2',\n",
       " 'AF3_theta1',\n",
       " 'AF3_theta2',\n",
       " 'AF3_alpha1',\n",
       " 'AF3_alpha2',\n",
       " 'AF3_beta1',\n",
       " 'AF3_beta2',\n",
       " 'AF3_gamma1',\n",
       " 'AF3_gamma2',\n",
       " 'F1_theta1',\n",
       " 'F1_theta2',\n",
       " 'F1_alpha1',\n",
       " 'F1_alpha2',\n",
       " 'F1_beta1',\n",
       " 'F1_beta2',\n",
       " 'F1_gamma1',\n",
       " 'F1_gamma2',\n",
       " 'F3_theta1',\n",
       " 'F3_theta2',\n",
       " 'F3_alpha1',\n",
       " 'F3_alpha2',\n",
       " 'F3_beta1',\n",
       " 'F3_beta2',\n",
       " 'F3_gamma1',\n",
       " 'F3_gamma2',\n",
       " 'F5_theta1',\n",
       " 'F5_theta2',\n",
       " 'F5_alpha1',\n",
       " 'F5_alpha2',\n",
       " 'F5_beta1',\n",
       " 'F5_beta2',\n",
       " 'F5_gamma1',\n",
       " 'F5_gamma2',\n",
       " 'F7_theta1',\n",
       " 'F7_theta2',\n",
       " 'F7_alpha1',\n",
       " 'F7_alpha2',\n",
       " 'F7_beta1',\n",
       " 'F7_beta2',\n",
       " 'F7_gamma1',\n",
       " 'F7_gamma2',\n",
       " 'FT7_theta1',\n",
       " 'FT7_theta2',\n",
       " 'FT7_alpha1',\n",
       " 'FT7_alpha2',\n",
       " 'FT7_beta1',\n",
       " 'FT7_beta2',\n",
       " 'FT7_gamma1',\n",
       " 'FT7_gamma2',\n",
       " 'FC5_theta1',\n",
       " 'FC5_theta2',\n",
       " 'FC5_alpha1',\n",
       " 'FC5_alpha2',\n",
       " 'FC5_beta1',\n",
       " 'FC5_beta2',\n",
       " 'FC5_gamma1',\n",
       " 'FC5_gamma2',\n",
       " 'FC3_theta1',\n",
       " 'FC3_theta2',\n",
       " 'FC3_alpha1',\n",
       " 'FC3_alpha2',\n",
       " 'FC3_beta1',\n",
       " 'FC3_beta2',\n",
       " 'FC3_gamma1',\n",
       " 'FC3_gamma2',\n",
       " 'FC1_theta1',\n",
       " 'FC1_theta2',\n",
       " 'FC1_alpha1',\n",
       " 'FC1_alpha2',\n",
       " 'FC1_beta1',\n",
       " 'FC1_beta2',\n",
       " 'FC1_gamma1',\n",
       " 'FC1_gamma2',\n",
       " 'C1_theta1',\n",
       " 'C1_theta2',\n",
       " 'C1_alpha1',\n",
       " 'C1_alpha2',\n",
       " 'C1_beta1',\n",
       " 'C1_beta2',\n",
       " 'C1_gamma1',\n",
       " 'C1_gamma2',\n",
       " 'C3_theta1',\n",
       " 'C3_theta2',\n",
       " 'C3_alpha1',\n",
       " 'C3_alpha2',\n",
       " 'C3_beta1',\n",
       " 'C3_beta2',\n",
       " 'C3_gamma1',\n",
       " 'C3_gamma2',\n",
       " 'C5_theta1',\n",
       " 'C5_theta2',\n",
       " 'C5_alpha1',\n",
       " 'C5_alpha2',\n",
       " 'C5_beta1',\n",
       " 'C5_beta2',\n",
       " 'C5_gamma1',\n",
       " 'C5_gamma2',\n",
       " 'T7_theta1',\n",
       " 'T7_theta2',\n",
       " 'T7_alpha1',\n",
       " 'T7_alpha2',\n",
       " 'T7_beta1',\n",
       " 'T7_beta2',\n",
       " 'T7_gamma1',\n",
       " 'T7_gamma2',\n",
       " 'TP7_theta1',\n",
       " 'TP7_theta2',\n",
       " 'TP7_alpha1',\n",
       " 'TP7_alpha2',\n",
       " 'TP7_beta1',\n",
       " 'TP7_beta2',\n",
       " 'TP7_gamma1',\n",
       " 'TP7_gamma2',\n",
       " 'CP5_theta1',\n",
       " 'CP5_theta2',\n",
       " 'CP5_alpha1',\n",
       " 'CP5_alpha2',\n",
       " 'CP5_beta1',\n",
       " 'CP5_beta2',\n",
       " 'CP5_gamma1',\n",
       " 'CP5_gamma2',\n",
       " 'CP3_theta1',\n",
       " 'CP3_theta2',\n",
       " 'CP3_alpha1',\n",
       " 'CP3_alpha2',\n",
       " 'CP3_beta1',\n",
       " 'CP3_beta2',\n",
       " 'CP3_gamma1',\n",
       " 'CP3_gamma2',\n",
       " 'CP1_theta1',\n",
       " 'CP1_theta2',\n",
       " 'CP1_alpha1',\n",
       " 'CP1_alpha2',\n",
       " 'CP1_beta1',\n",
       " 'CP1_beta2',\n",
       " 'CP1_gamma1',\n",
       " 'CP1_gamma2',\n",
       " 'P1_theta1',\n",
       " 'P1_theta2',\n",
       " 'P1_alpha1',\n",
       " 'P1_alpha2',\n",
       " 'P1_beta1',\n",
       " 'P1_beta2',\n",
       " 'P1_gamma1',\n",
       " 'P1_gamma2',\n",
       " 'P3_theta1',\n",
       " 'P3_theta2',\n",
       " 'P3_alpha1',\n",
       " 'P3_alpha2',\n",
       " 'P3_beta1',\n",
       " 'P3_beta2',\n",
       " 'P3_gamma1',\n",
       " 'P3_gamma2',\n",
       " 'P5_theta1',\n",
       " 'P5_theta2',\n",
       " 'P5_alpha1',\n",
       " 'P5_alpha2',\n",
       " 'P5_beta1',\n",
       " 'P5_beta2',\n",
       " 'P5_gamma1',\n",
       " 'P5_gamma2',\n",
       " 'P7_theta1',\n",
       " 'P7_theta2',\n",
       " 'P7_alpha1',\n",
       " 'P7_alpha2',\n",
       " 'P7_beta1',\n",
       " 'P7_beta2',\n",
       " 'P7_gamma1',\n",
       " 'P7_gamma2',\n",
       " 'P9_theta1',\n",
       " 'P9_theta2',\n",
       " 'P9_alpha1',\n",
       " 'P9_alpha2',\n",
       " 'P9_beta1',\n",
       " 'P9_beta2',\n",
       " 'P9_gamma1',\n",
       " 'P9_gamma2',\n",
       " 'PO7_theta1',\n",
       " 'PO7_theta2',\n",
       " 'PO7_alpha1',\n",
       " 'PO7_alpha2',\n",
       " 'PO7_beta1',\n",
       " 'PO7_beta2',\n",
       " 'PO7_gamma1',\n",
       " 'PO7_gamma2',\n",
       " 'PO3_theta1',\n",
       " 'PO3_theta2',\n",
       " 'PO3_alpha1',\n",
       " 'PO3_alpha2',\n",
       " 'PO3_beta1',\n",
       " 'PO3_beta2',\n",
       " 'PO3_gamma1',\n",
       " 'PO3_gamma2',\n",
       " 'O1_theta1',\n",
       " 'O1_theta2',\n",
       " 'O1_alpha1',\n",
       " 'O1_alpha2',\n",
       " 'O1_beta1',\n",
       " 'O1_beta2',\n",
       " 'O1_gamma1',\n",
       " 'O1_gamma2',\n",
       " 'Iz_theta1',\n",
       " 'Iz_theta2',\n",
       " 'Iz_alpha1',\n",
       " 'Iz_alpha2',\n",
       " 'Iz_beta1',\n",
       " 'Iz_beta2',\n",
       " 'Iz_gamma1',\n",
       " 'Iz_gamma2',\n",
       " 'Oz_theta1',\n",
       " 'Oz_theta2',\n",
       " 'Oz_alpha1',\n",
       " 'Oz_alpha2',\n",
       " 'Oz_beta1',\n",
       " 'Oz_beta2',\n",
       " 'Oz_gamma1',\n",
       " 'Oz_gamma2',\n",
       " 'POz_theta1',\n",
       " 'POz_theta2',\n",
       " 'POz_alpha1',\n",
       " 'POz_alpha2',\n",
       " 'POz_beta1',\n",
       " 'POz_beta2',\n",
       " 'POz_gamma1',\n",
       " 'POz_gamma2',\n",
       " 'Pz_theta1',\n",
       " 'Pz_theta2',\n",
       " 'Pz_alpha1',\n",
       " 'Pz_alpha2',\n",
       " 'Pz_beta1',\n",
       " 'Pz_beta2',\n",
       " 'Pz_gamma1',\n",
       " 'Pz_gamma2',\n",
       " 'CPz_theta1',\n",
       " 'CPz_theta2',\n",
       " 'CPz_alpha1',\n",
       " 'CPz_alpha2',\n",
       " 'CPz_beta1',\n",
       " 'CPz_beta2',\n",
       " 'CPz_gamma1',\n",
       " 'CPz_gamma2',\n",
       " 'Fpz_theta1',\n",
       " 'Fpz_theta2',\n",
       " 'Fpz_alpha1',\n",
       " 'Fpz_alpha2',\n",
       " 'Fpz_beta1',\n",
       " 'Fpz_beta2',\n",
       " 'Fpz_gamma1',\n",
       " 'Fpz_gamma2',\n",
       " 'Fp2_theta1',\n",
       " 'Fp2_theta2',\n",
       " 'Fp2_alpha1',\n",
       " 'Fp2_alpha2',\n",
       " 'Fp2_beta1',\n",
       " 'Fp2_beta2',\n",
       " 'Fp2_gamma1',\n",
       " 'Fp2_gamma2',\n",
       " 'AF8_theta1',\n",
       " 'AF8_theta2',\n",
       " 'AF8_alpha1',\n",
       " 'AF8_alpha2',\n",
       " 'AF8_beta1',\n",
       " 'AF8_beta2',\n",
       " 'AF8_gamma1',\n",
       " 'AF8_gamma2',\n",
       " 'AF4_theta1',\n",
       " 'AF4_theta2',\n",
       " 'AF4_alpha1',\n",
       " 'AF4_alpha2',\n",
       " 'AF4_beta1',\n",
       " 'AF4_beta2',\n",
       " 'AF4_gamma1',\n",
       " 'AF4_gamma2',\n",
       " 'Afz_theta1',\n",
       " 'Afz_theta2',\n",
       " 'Afz_alpha1',\n",
       " 'Afz_alpha2',\n",
       " 'Afz_beta1',\n",
       " 'Afz_beta2',\n",
       " 'Afz_gamma1',\n",
       " 'Afz_gamma2',\n",
       " 'Fz_theta1',\n",
       " 'Fz_theta2',\n",
       " 'Fz_alpha1',\n",
       " 'Fz_alpha2',\n",
       " 'Fz_beta1',\n",
       " 'Fz_beta2',\n",
       " 'Fz_gamma1',\n",
       " 'Fz_gamma2',\n",
       " 'F2_theta1',\n",
       " 'F2_theta2',\n",
       " 'F2_alpha1',\n",
       " 'F2_alpha2',\n",
       " 'F2_beta1',\n",
       " 'F2_beta2',\n",
       " 'F2_gamma1',\n",
       " 'F2_gamma2',\n",
       " 'F4_theta1',\n",
       " 'F4_theta2',\n",
       " 'F4_alpha1',\n",
       " 'F4_alpha2',\n",
       " 'F4_beta1',\n",
       " 'F4_beta2',\n",
       " 'F4_gamma1',\n",
       " 'F4_gamma2',\n",
       " 'F6_theta1',\n",
       " 'F6_theta2',\n",
       " 'F6_alpha1',\n",
       " 'F6_alpha2',\n",
       " 'F6_beta1',\n",
       " 'F6_beta2',\n",
       " 'F6_gamma1',\n",
       " 'F6_gamma2',\n",
       " 'F8_theta1',\n",
       " 'F8_theta2',\n",
       " 'F8_alpha1',\n",
       " 'F8_alpha2',\n",
       " 'F8_beta1',\n",
       " 'F8_beta2',\n",
       " 'F8_gamma1',\n",
       " 'F8_gamma2',\n",
       " 'FT8_theta1',\n",
       " 'FT8_theta2',\n",
       " 'FT8_alpha1',\n",
       " 'FT8_alpha2',\n",
       " 'FT8_beta1',\n",
       " 'FT8_beta2',\n",
       " 'FT8_gamma1',\n",
       " 'FT8_gamma2',\n",
       " 'FC6_theta1',\n",
       " 'FC6_theta2',\n",
       " 'FC6_alpha1',\n",
       " 'FC6_alpha2',\n",
       " 'FC6_beta1',\n",
       " 'FC6_beta2',\n",
       " 'FC6_gamma1',\n",
       " 'FC6_gamma2',\n",
       " 'FC4_theta1',\n",
       " 'FC4_theta2',\n",
       " 'FC4_alpha1',\n",
       " 'FC4_alpha2',\n",
       " 'FC4_beta1',\n",
       " 'FC4_beta2',\n",
       " 'FC4_gamma1',\n",
       " 'FC4_gamma2',\n",
       " 'FC2_theta1',\n",
       " 'FC2_theta2',\n",
       " 'FC2_alpha1',\n",
       " 'FC2_alpha2',\n",
       " 'FC2_beta1',\n",
       " 'FC2_beta2',\n",
       " 'FC2_gamma1',\n",
       " 'FC2_gamma2',\n",
       " 'FCz_theta1',\n",
       " 'FCz_theta2',\n",
       " 'FCz_alpha1',\n",
       " 'FCz_alpha2',\n",
       " 'FCz_beta1',\n",
       " 'FCz_beta2',\n",
       " 'FCz_gamma1',\n",
       " 'FCz_gamma2',\n",
       " 'Cz_theta1',\n",
       " 'Cz_theta2',\n",
       " 'Cz_alpha1',\n",
       " 'Cz_alpha2',\n",
       " 'Cz_beta1',\n",
       " 'Cz_beta2',\n",
       " 'Cz_gamma1',\n",
       " 'Cz_gamma2',\n",
       " 'C2_theta1',\n",
       " 'C2_theta2',\n",
       " 'C2_alpha1',\n",
       " 'C2_alpha2',\n",
       " 'C2_beta1',\n",
       " 'C2_beta2',\n",
       " 'C2_gamma1',\n",
       " 'C2_gamma2',\n",
       " 'C4_theta1',\n",
       " 'C4_theta2',\n",
       " 'C4_alpha1',\n",
       " 'C4_alpha2',\n",
       " 'C4_beta1',\n",
       " 'C4_beta2',\n",
       " 'C4_gamma1',\n",
       " 'C4_gamma2',\n",
       " 'C6_theta1',\n",
       " 'C6_theta2',\n",
       " 'C6_alpha1',\n",
       " 'C6_alpha2',\n",
       " 'C6_beta1',\n",
       " 'C6_beta2',\n",
       " 'C6_gamma1',\n",
       " 'C6_gamma2',\n",
       " 'T8_theta1',\n",
       " 'T8_theta2',\n",
       " 'T8_alpha1',\n",
       " 'T8_alpha2',\n",
       " 'T8_beta1',\n",
       " 'T8_beta2',\n",
       " 'T8_gamma1',\n",
       " 'T8_gamma2',\n",
       " 'TP8_theta1',\n",
       " 'TP8_theta2',\n",
       " 'TP8_alpha1',\n",
       " 'TP8_alpha2',\n",
       " 'TP8_beta1',\n",
       " 'TP8_beta2',\n",
       " 'TP8_gamma1',\n",
       " 'TP8_gamma2',\n",
       " 'CP6_theta1',\n",
       " 'CP6_theta2',\n",
       " 'CP6_alpha1',\n",
       " 'CP6_alpha2',\n",
       " 'CP6_beta1',\n",
       " 'CP6_beta2',\n",
       " 'CP6_gamma1',\n",
       " 'CP6_gamma2',\n",
       " 'CP4_theta1',\n",
       " 'CP4_theta2',\n",
       " 'CP4_alpha1',\n",
       " 'CP4_alpha2',\n",
       " 'CP4_beta1',\n",
       " 'CP4_beta2',\n",
       " 'CP4_gamma1',\n",
       " 'CP4_gamma2',\n",
       " 'CP2_theta1',\n",
       " 'CP2_theta2',\n",
       " 'CP2_alpha1',\n",
       " 'CP2_alpha2',\n",
       " 'CP2_beta1',\n",
       " 'CP2_beta2',\n",
       " 'CP2_gamma1',\n",
       " 'CP2_gamma2',\n",
       " 'P2_theta1',\n",
       " 'P2_theta2',\n",
       " 'P2_alpha1',\n",
       " 'P2_alpha2',\n",
       " 'P2_beta1',\n",
       " 'P2_beta2',\n",
       " 'P2_gamma1',\n",
       " 'P2_gamma2',\n",
       " 'P4_theta1',\n",
       " 'P4_theta2',\n",
       " 'P4_alpha1',\n",
       " 'P4_alpha2',\n",
       " 'P4_beta1',\n",
       " 'P4_beta2',\n",
       " 'P4_gamma1',\n",
       " 'P4_gamma2',\n",
       " 'P6_theta1',\n",
       " 'P6_theta2',\n",
       " 'P6_alpha1',\n",
       " 'P6_alpha2',\n",
       " 'P6_beta1',\n",
       " 'P6_beta2',\n",
       " 'P6_gamma1',\n",
       " 'P6_gamma2',\n",
       " 'P8_theta1',\n",
       " 'P8_theta2',\n",
       " 'P8_alpha1',\n",
       " 'P8_alpha2',\n",
       " 'P8_beta1',\n",
       " 'P8_beta2',\n",
       " 'P8_gamma1',\n",
       " 'P8_gamma2',\n",
       " 'P10_theta1',\n",
       " 'P10_theta2',\n",
       " 'P10_alpha1',\n",
       " 'P10_alpha2',\n",
       " 'P10_beta1',\n",
       " 'P10_beta2',\n",
       " 'P10_gamma1',\n",
       " 'P10_gamma2',\n",
       " 'PO8_theta1',\n",
       " 'PO8_theta2',\n",
       " 'PO8_alpha1',\n",
       " 'PO8_alpha2',\n",
       " 'PO8_beta1',\n",
       " 'PO8_beta2',\n",
       " 'PO8_gamma1',\n",
       " 'PO8_gamma2',\n",
       " 'PO4_theta1',\n",
       " 'PO4_theta2',\n",
       " 'PO4_alpha1',\n",
       " 'PO4_alpha2',\n",
       " 'PO4_beta1',\n",
       " 'PO4_beta2',\n",
       " 'PO4_gamma1',\n",
       " 'PO4_gamma2',\n",
       " 'O2_theta1',\n",
       " 'O2_theta2',\n",
       " 'O2_alpha1',\n",
       " 'O2_alpha2',\n",
       " 'O2_beta1',\n",
       " 'O2_beta2',\n",
       " 'O2_gamma1',\n",
       " 'O2_gamma2',\n",
       " 'label',\n",
       " 'subject_id']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc0d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Feature set: EEG + Eye ==========\n",
      "\n",
      "=== Model: logreg ===\n",
      "  Subject s10014: acc=0.558, prec=0.565, f1=0.531, auc=0.537\n",
      "  Subject s10052: acc=0.533, prec=1.000, f1=0.125, auc=0.453\n",
      "  Subject s10059: acc=0.857, prec=0.857, f1=0.857, auc=0.918\n",
      "  Subject s10073: acc=0.679, prec=0.619, f1=0.743, auc=0.668\n",
      "  Subject s10081: acc=0.729, prec=0.789, f1=0.698, auc=0.760\n",
      "  Subject s10084: acc=0.643, prec=0.875, f1=0.483, auc=0.728\n",
      "  Subject s10085: acc=0.712, prec=0.824, f1=0.651, auc=0.717\n",
      "  Subject s10089: acc=0.545, prec=0.600, f1=0.375, auc=0.661\n",
      "  Subject s10094: acc=1.000, prec=1.000, f1=1.000, auc=1.000\n",
      "  Subject s10100: acc=0.484, prec=0.467, f1=0.304, auc=0.454\n",
      "  Subject s10103: acc=0.429, prec=0.455, f1=0.556, auc=0.551\n",
      "  Subject s10110: acc=0.594, prec=0.636, f1=0.519, auc=0.613\n",
      "  Subject s10111: acc=0.484, prec=0.492, f1=0.652, auc=0.446\n",
      "  Subject s10115: acc=0.518, prec=0.520, f1=0.491, auc=0.545\n",
      "  Subject s10117: acc=0.500, prec=0.500, f1=0.154, auc=0.529\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.632, auc=0.520\n",
      "  Subject s10125: acc=0.500, prec=0.500, f1=0.667, auc=0.724\n",
      "  Subject s10138: acc=0.519, prec=0.529, f1=0.409, auc=0.558\n",
      "  Subject s10139: acc=0.722, prec=0.667, f1=0.762, auc=0.861\n",
      "  Subject s10141: acc=0.679, prec=0.778, f1=0.609, auc=0.730\n",
      "  Subject s10144: acc=0.429, prec=0.462, f1=0.600, auc=0.735\n",
      "  Subject s10145: acc=0.537, prec=0.538, f1=0.528, auc=0.543\n",
      "  Subject s10148: acc=0.676, prec=0.625, f1=0.732, auc=0.751\n",
      "  Subject s10153: acc=0.478, prec=0.467, f1=0.368, auc=0.456\n",
      "  Subject s10156: acc=0.742, prec=0.826, f1=0.704, auc=0.874\n",
      "  Subject s10158: acc=0.656, prec=0.604, f1=0.725, auc=0.729\n",
      "  Subject s10159: acc=0.567, prec=0.833, f1=0.278, auc=0.702\n",
      "  Subject s10160: acc=0.538, prec=1.000, f1=0.143, auc=0.444\n",
      "  Subject s10165: acc=0.500, prec=0.000, f1=0.000, auc=0.454\n",
      "  Subject s10173: acc=0.500, prec=0.500, f1=0.667, auc=0.880\n",
      "  Subject s10177: acc=0.425, prec=0.452, f1=0.549, auc=0.475\n",
      "  Subject s10178: acc=0.538, prec=1.000, f1=0.143, auc=0.556\n",
      "  Subject s10180: acc=0.742, prec=0.674, f1=0.784, auc=0.777\n",
      "  Subject s10181: acc=0.485, prec=0.492, f1=0.646, auc=0.567\n",
      "  Subject s10183: acc=0.559, prec=0.550, f1=0.595, auc=0.505\n",
      "  Subject s10185: acc=0.500, prec=0.500, f1=0.667, auc=0.000\n",
      "  Subject s10186: acc=0.577, prec=0.545, f1=0.686, auc=0.669\n",
      "  Subject s10188: acc=0.429, prec=0.457, f1=0.571, auc=0.605\n",
      "  Subject s10192: acc=0.561, prec=0.577, f1=0.508, auc=0.593\n",
      "  Subject s10195: acc=0.636, prec=0.800, f1=0.500, auc=0.646\n",
      "  Subject s10196: acc=0.800, prec=0.714, f1=0.833, auc=0.840\n",
      "  Subject s10197: acc=0.722, prec=0.667, f1=0.762, auc=0.827\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.468, auc=0.531\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.250, auc=0.528\n",
      "Mean over subjects — acc=0.586, prec=0.624, f1=0.544, auc=0.629\n",
      "\n",
      "=== Model: linear_svc ===\n",
      "  Subject s10014: acc=0.558, prec=0.565, f1=0.531, auc=0.531\n",
      "  Subject s10052: acc=0.533, prec=1.000, f1=0.125, auc=0.458\n",
      "  Subject s10059: acc=0.857, prec=1.000, f1=0.833, auc=0.918\n",
      "  Subject s10073: acc=0.679, prec=0.619, f1=0.743, auc=0.668\n",
      "  Subject s10081: acc=0.729, prec=0.789, f1=0.698, auc=0.762\n",
      "  Subject s10084: acc=0.619, prec=0.857, f1=0.429, auc=0.728\n",
      "  Subject s10085: acc=0.692, prec=0.778, f1=0.636, auc=0.716\n",
      "  Subject s10089: acc=0.591, prec=0.667, f1=0.471, auc=0.686\n",
      "  Subject s10094: acc=0.750, prec=1.000, f1=0.667, auc=1.000\n",
      "  Subject s10100: acc=0.484, prec=0.467, f1=0.304, auc=0.459\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.588, auc=0.571\n",
      "  Subject s10110: acc=0.594, prec=0.636, f1=0.519, auc=0.598\n",
      "  Subject s10111: acc=0.484, prec=0.492, f1=0.652, auc=0.446\n",
      "  Subject s10115: acc=0.518, prec=0.520, f1=0.491, auc=0.552\n",
      "  Subject s10117: acc=0.500, prec=0.500, f1=0.154, auc=0.531\n",
      "  Subject s10121: acc=0.464, prec=0.480, f1=0.615, auc=0.520\n",
      "  Subject s10125: acc=0.500, prec=0.500, f1=0.667, auc=0.719\n",
      "  Subject s10138: acc=0.519, prec=0.529, f1=0.409, auc=0.557\n",
      "  Subject s10139: acc=0.722, prec=0.667, f1=0.762, auc=0.873\n",
      "  Subject s10141: acc=0.679, prec=0.778, f1=0.609, auc=0.714\n",
      "  Subject s10144: acc=0.429, prec=0.462, f1=0.600, auc=0.735\n",
      "  Subject s10145: acc=0.537, prec=0.538, f1=0.528, auc=0.549\n",
      "  Subject s10148: acc=0.676, prec=0.625, f1=0.732, auc=0.785\n",
      "  Subject s10153: acc=0.522, prec=0.529, f1=0.450, auc=0.478\n",
      "  Subject s10156: acc=0.758, prec=0.864, f1=0.717, auc=0.874\n",
      "  Subject s10158: acc=0.656, prec=0.614, f1=0.711, auc=0.734\n",
      "  Subject s10159: acc=0.567, prec=0.833, f1=0.278, auc=0.712\n",
      "  Subject s10160: acc=0.538, prec=1.000, f1=0.143, auc=0.456\n",
      "  Subject s10165: acc=0.500, prec=0.000, f1=0.000, auc=0.452\n",
      "  Subject s10173: acc=0.500, prec=0.500, f1=0.667, auc=0.840\n",
      "  Subject s10177: acc=0.475, prec=0.483, f1=0.571, auc=0.478\n",
      "  Subject s10178: acc=0.538, prec=1.000, f1=0.143, auc=0.556\n",
      "  Subject s10180: acc=0.742, prec=0.674, f1=0.784, auc=0.780\n",
      "  Subject s10181: acc=0.500, prec=0.500, f1=0.653, auc=0.565\n",
      "  Subject s10183: acc=0.588, prec=0.571, f1=0.632, auc=0.509\n",
      "  Subject s10185: acc=0.500, prec=0.500, f1=0.667, auc=0.000\n",
      "  Subject s10186: acc=0.577, prec=0.545, f1=0.686, auc=0.692\n",
      "  Subject s10188: acc=0.429, prec=0.457, f1=0.571, auc=0.594\n",
      "  Subject s10192: acc=0.561, prec=0.577, f1=0.508, auc=0.594\n",
      "  Subject s10195: acc=0.652, prec=0.812, f1=0.531, auc=0.636\n",
      "  Subject s10196: acc=0.800, prec=0.714, f1=0.833, auc=0.840\n",
      "  Subject s10197: acc=0.722, prec=0.667, f1=0.762, auc=0.827\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.444, auc=0.531\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.250, auc=0.556\n",
      "Mean over subjects — acc=0.585, prec=0.632, f1=0.540, auc=0.631\n",
      "\n",
      "=== Model: rbf_svc ===\n",
      "  Subject s10014: acc=0.558, prec=0.533, f1=0.676, auc=0.626\n",
      "  Subject s10052: acc=0.467, prec=0.400, f1=0.200, auc=0.498\n",
      "  Subject s10059: acc=0.643, prec=1.000, f1=0.444, auc=0.878\n",
      "  Subject s10073: acc=0.643, prec=0.611, f1=0.688, auc=0.781\n",
      "  Subject s10081: acc=0.604, prec=0.600, f1=0.612, auc=0.622\n",
      "  Subject s10084: acc=0.571, prec=0.588, f1=0.526, auc=0.598\n",
      "  Subject s10085: acc=0.615, prec=0.750, f1=0.474, auc=0.673\n",
      "  Subject s10089: acc=0.455, prec=0.400, f1=0.250, auc=0.566\n",
      "  Subject s10094: acc=0.750, prec=0.667, f1=0.800, auc=0.750\n",
      "  Subject s10100: acc=0.387, prec=0.394, f1=0.406, auc=0.417\n",
      "  Subject s10103: acc=0.571, prec=0.545, f1=0.667, auc=0.633\n",
      "  Subject s10110: acc=0.531, prec=0.545, f1=0.444, auc=0.605\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.667, auc=0.518\n",
      "  Subject s10115: acc=0.554, prec=0.600, f1=0.419, auc=0.526\n",
      "  Subject s10117: acc=0.477, prec=0.400, f1=0.148, auc=0.460\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.650, auc=0.546\n",
      "  Subject s10125: acc=0.562, prec=0.538, f1=0.667, auc=0.691\n",
      "  Subject s10138: acc=0.519, prec=0.526, f1=0.435, auc=0.497\n",
      "  Subject s10139: acc=0.528, prec=0.514, f1=0.679, auc=0.741\n",
      "  Subject s10141: acc=0.643, prec=0.833, f1=0.500, auc=0.742\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.533, auc=0.673\n",
      "  Subject s10145: acc=0.611, prec=0.625, f1=0.588, auc=0.631\n",
      "  Subject s10148: acc=0.676, prec=0.650, f1=0.703, auc=0.737\n",
      "  Subject s10153: acc=0.543, prec=0.571, f1=0.432, auc=0.584\n",
      "  Subject s10156: acc=0.661, prec=0.727, f1=0.604, auc=0.824\n",
      "  Subject s10158: acc=0.562, prec=0.538, f1=0.667, auc=0.708\n",
      "  Subject s10159: acc=0.567, prec=1.000, f1=0.235, auc=0.693\n",
      "  Subject s10160: acc=0.731, prec=0.750, f1=0.720, auc=0.746\n",
      "  Subject s10165: acc=0.500, prec=0.000, f1=0.000, auc=0.474\n",
      "  Subject s10173: acc=0.700, prec=0.667, f1=0.727, auc=0.660\n",
      "  Subject s10177: acc=0.500, prec=0.500, f1=0.412, auc=0.507\n",
      "  Subject s10178: acc=0.577, prec=1.000, f1=0.267, auc=0.426\n",
      "  Subject s10180: acc=0.629, prec=0.654, f1=0.596, auc=0.721\n",
      "  Subject s10181: acc=0.515, prec=0.508, f1=0.660, auc=0.554\n",
      "  Subject s10183: acc=0.500, prec=0.500, f1=0.653, auc=0.728\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.250\n",
      "  Subject s10186: acc=0.615, prec=0.588, f1=0.667, auc=0.731\n",
      "  Subject s10188: acc=0.619, prec=0.600, f1=0.652, auc=0.626\n",
      "  Subject s10192: acc=0.606, prec=0.600, f1=0.618, auc=0.627\n",
      "  Subject s10195: acc=0.606, prec=0.769, f1=0.435, auc=0.689\n",
      "  Subject s10196: acc=0.700, prec=0.667, f1=0.727, auc=0.880\n",
      "  Subject s10197: acc=0.611, prec=0.562, f1=0.720, auc=0.852\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.627, auc=0.502\n",
      "  Subject s10202: acc=0.667, prec=0.750, f1=0.600, auc=0.708\n",
      "Mean over subjects — acc=0.569, prec=0.591, f1=0.536, auc=0.634\n",
      "\n",
      "=== Model: random_forest ===\n",
      "  Subject s10014: acc=0.500, prec=0.500, f1=0.581, auc=0.532\n",
      "  Subject s10052: acc=0.567, prec=0.600, f1=0.480, auc=0.544\n",
      "  Subject s10059: acc=0.714, prec=1.000, f1=0.600, auc=0.796\n",
      "  Subject s10073: acc=0.500, prec=0.500, f1=0.611, auc=0.536\n",
      "  Subject s10081: acc=0.583, prec=0.591, f1=0.565, auc=0.641\n",
      "  Subject s10084: acc=0.619, prec=0.632, f1=0.600, auc=0.613\n",
      "  Subject s10085: acc=0.692, prec=0.679, f1=0.704, auc=0.704\n",
      "  Subject s10089: acc=0.636, prec=0.615, f1=0.667, auc=0.628\n",
      "  Subject s10094: acc=0.250, prec=0.333, f1=0.400, auc=0.500\n",
      "  Subject s10100: acc=0.468, prec=0.464, f1=0.441, auc=0.456\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.588, auc=0.551\n",
      "  Subject s10110: acc=0.406, prec=0.400, f1=0.387, auc=0.436\n",
      "  Subject s10111: acc=0.565, prec=0.571, f1=0.542, auc=0.559\n",
      "  Subject s10115: acc=0.625, prec=0.595, f1=0.677, auc=0.651\n",
      "  Subject s10117: acc=0.568, prec=0.579, f1=0.537, auc=0.569\n",
      "  Subject s10121: acc=0.464, prec=0.480, f1=0.615, auc=0.462\n",
      "  Subject s10125: acc=0.542, prec=0.531, f1=0.607, auc=0.628\n",
      "  Subject s10138: acc=0.426, prec=0.429, f1=0.436, auc=0.392\n",
      "  Subject s10139: acc=0.528, prec=0.515, f1=0.667, auc=0.565\n",
      "  Subject s10141: acc=0.500, prec=0.500, f1=0.364, auc=0.668\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.632, auc=0.571\n",
      "  Subject s10145: acc=0.500, prec=0.500, f1=0.571, auc=0.448\n",
      "  Subject s10148: acc=0.706, prec=0.667, f1=0.737, auc=0.834\n",
      "  Subject s10153: acc=0.457, prec=0.464, f1=0.510, auc=0.448\n",
      "  Subject s10156: acc=0.758, prec=0.786, f1=0.746, auc=0.862\n",
      "  Subject s10158: acc=0.562, prec=0.543, f1=0.641, auc=0.651\n",
      "  Subject s10159: acc=0.667, prec=0.692, f1=0.643, auc=0.697\n",
      "  Subject s10160: acc=0.654, prec=0.643, f1=0.667, auc=0.754\n",
      "  Subject s10165: acc=0.421, prec=0.333, f1=0.214, auc=0.428\n",
      "  Subject s10173: acc=0.700, prec=0.625, f1=0.769, auc=0.680\n",
      "  Subject s10177: acc=0.450, prec=0.444, f1=0.421, auc=0.395\n",
      "  Subject s10178: acc=0.500, prec=0.000, f1=0.000, auc=0.462\n",
      "  Subject s10180: acc=0.694, prec=0.658, f1=0.725, auc=0.740\n",
      "  Subject s10181: acc=0.455, prec=0.475, f1=0.617, auc=0.464\n",
      "  Subject s10183: acc=0.647, prec=0.667, f1=0.625, auc=0.711\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=1.000\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.606, auc=0.654\n",
      "  Subject s10188: acc=0.548, prec=0.531, f1=0.642, auc=0.598\n",
      "  Subject s10192: acc=0.515, prec=0.513, f1=0.556, auc=0.559\n",
      "  Subject s10195: acc=0.591, prec=0.588, f1=0.597, auc=0.624\n",
      "  Subject s10196: acc=0.400, prec=0.429, f1=0.500, auc=0.660\n",
      "  Subject s10197: acc=0.667, prec=0.615, f1=0.727, auc=0.821\n",
      "  Subject s10200: acc=0.440, prec=0.459, f1=0.548, auc=0.358\n",
      "  Subject s10202: acc=0.583, prec=0.600, f1=0.545, auc=0.500\n",
      "Mean over subjects — acc=0.553, prec=0.544, f1=0.571, auc=0.599\n",
      "\n",
      "=== Model: gradient_boosting ===\n",
      "  Subject s10014: acc=0.462, prec=0.464, f1=0.481, auc=0.528\n",
      "  Subject s10052: acc=0.533, prec=0.600, f1=0.300, auc=0.582\n",
      "  Subject s10059: acc=0.643, prec=0.750, f1=0.545, auc=0.673\n",
      "  Subject s10073: acc=0.679, prec=0.632, f1=0.727, auc=0.582\n",
      "  Subject s10081: acc=0.521, prec=0.545, f1=0.343, auc=0.566\n",
      "  Subject s10084: acc=0.619, prec=0.727, f1=0.500, auc=0.619\n",
      "  Subject s10085: acc=0.558, prec=0.571, f1=0.511, auc=0.586\n",
      "  Subject s10089: acc=0.500, prec=0.500, f1=0.560, auc=0.339\n",
      "  Subject s10094: acc=0.250, prec=0.000, f1=0.000, auc=0.500\n",
      "  Subject s10100: acc=0.500, prec=0.500, f1=0.475, auc=0.475\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.533, auc=0.592\n",
      "  Subject s10110: acc=0.656, prec=0.692, f1=0.621, auc=0.656\n",
      "  Subject s10111: acc=0.548, prec=0.537, f1=0.611, auc=0.546\n",
      "  Subject s10115: acc=0.571, prec=0.567, f1=0.586, auc=0.566\n",
      "  Subject s10117: acc=0.432, prec=0.435, f1=0.444, auc=0.479\n",
      "  Subject s10121: acc=0.429, prec=0.462, f1=0.600, auc=0.398\n",
      "  Subject s10125: acc=0.542, prec=0.528, f1=0.633, auc=0.623\n",
      "  Subject s10138: acc=0.444, prec=0.457, f1=0.516, auc=0.476\n",
      "  Subject s10139: acc=0.667, prec=0.607, f1=0.739, auc=0.648\n",
      "  Subject s10141: acc=0.714, prec=0.688, f1=0.733, auc=0.786\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.632, auc=0.694\n",
      "  Subject s10145: acc=0.537, prec=0.528, f1=0.603, auc=0.490\n",
      "  Subject s10148: acc=0.676, prec=0.636, f1=0.718, auc=0.761\n",
      "  Subject s10153: acc=0.522, prec=0.533, f1=0.421, auc=0.484\n",
      "  Subject s10156: acc=0.790, prec=0.765, f1=0.800, auc=0.867\n",
      "  Subject s10158: acc=0.578, prec=0.564, f1=0.620, auc=0.627\n",
      "  Subject s10159: acc=0.567, prec=0.625, f1=0.435, auc=0.620\n",
      "  Subject s10160: acc=0.654, prec=0.643, f1=0.667, auc=0.621\n",
      "  Subject s10165: acc=0.500, prec=0.500, f1=0.095, auc=0.496\n",
      "  Subject s10173: acc=0.400, prec=0.444, f1=0.571, auc=0.440\n",
      "  Subject s10177: acc=0.575, prec=0.615, f1=0.485, auc=0.522\n",
      "  Subject s10178: acc=0.500, prec=0.500, f1=0.133, auc=0.621\n",
      "  Subject s10180: acc=0.548, prec=0.541, f1=0.588, auc=0.571\n",
      "  Subject s10181: acc=0.561, prec=0.538, f1=0.659, auc=0.586\n",
      "  Subject s10183: acc=0.412, prec=0.435, f1=0.500, auc=0.311\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=1.000\n",
      "  Subject s10186: acc=0.615, prec=0.579, f1=0.688, auc=0.680\n",
      "  Subject s10188: acc=0.500, prec=0.500, f1=0.604, auc=0.601\n",
      "  Subject s10192: acc=0.636, prec=0.645, f1=0.625, auc=0.653\n",
      "  Subject s10195: acc=0.530, prec=0.536, f1=0.492, auc=0.577\n",
      "  Subject s10196: acc=0.600, prec=0.571, f1=0.667, auc=0.840\n",
      "  Subject s10197: acc=0.611, prec=0.583, f1=0.667, auc=0.790\n",
      "  Subject s10200: acc=0.560, prec=0.543, f1=0.633, auc=0.640\n",
      "  Subject s10202: acc=0.583, prec=0.667, f1=0.444, auc=0.528\n",
      "Mean over subjects — acc=0.556, prec=0.555, f1=0.546, auc=0.596\n",
      "\n",
      "=== Model: knn ===\n",
      "  Subject s10014: acc=0.500, prec=0.500, f1=0.567, auc=0.532\n",
      "  Subject s10052: acc=0.367, prec=0.333, f1=0.296, auc=0.318\n",
      "  Subject s10059: acc=0.571, prec=0.571, f1=0.571, auc=0.612\n",
      "  Subject s10073: acc=0.571, prec=0.571, f1=0.571, auc=0.582\n",
      "  Subject s10081: acc=0.604, prec=0.586, f1=0.642, auc=0.589\n",
      "  Subject s10084: acc=0.524, prec=0.522, f1=0.545, auc=0.500\n",
      "  Subject s10085: acc=0.365, prec=0.316, f1=0.267, auc=0.351\n",
      "  Subject s10089: acc=0.318, prec=0.333, f1=0.348, auc=0.277\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.667, auc=0.750\n",
      "  Subject s10100: acc=0.435, prec=0.433, f1=0.426, auc=0.393\n",
      "  Subject s10103: acc=0.571, prec=0.556, f1=0.625, auc=0.571\n",
      "  Subject s10110: acc=0.438, prec=0.375, f1=0.250, auc=0.465\n",
      "  Subject s10111: acc=0.371, prec=0.409, f1=0.480, auc=0.400\n",
      "  Subject s10115: acc=0.429, prec=0.441, f1=0.484, auc=0.420\n",
      "  Subject s10117: acc=0.455, prec=0.444, f1=0.400, auc=0.405\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.611, auc=0.426\n",
      "  Subject s10125: acc=0.521, prec=1.000, f1=0.080, auc=0.444\n",
      "  Subject s10138: acc=0.556, prec=0.600, f1=0.429, auc=0.552\n",
      "  Subject s10139: acc=0.528, prec=0.517, f1=0.638, auc=0.505\n",
      "  Subject s10141: acc=0.571, prec=0.583, f1=0.538, auc=0.543\n",
      "  Subject s10144: acc=0.429, prec=0.444, f1=0.500, auc=0.541\n",
      "  Subject s10145: acc=0.481, prec=0.476, f1=0.417, auc=0.510\n",
      "  Subject s10148: acc=0.441, prec=0.458, f1=0.537, auc=0.491\n",
      "  Subject s10153: acc=0.370, prec=0.385, f1=0.408, auc=0.388\n",
      "  Subject s10156: acc=0.516, prec=0.524, f1=0.423, auc=0.549\n",
      "  Subject s10158: acc=0.438, prec=0.441, f1=0.455, auc=0.448\n",
      "  Subject s10159: acc=0.533, prec=0.600, f1=0.300, auc=0.588\n",
      "  Subject s10160: acc=0.423, prec=0.444, f1=0.516, auc=0.388\n",
      "  Subject s10165: acc=0.526, prec=0.538, f1=0.438, auc=0.528\n",
      "  Subject s10173: acc=0.400, prec=0.400, f1=0.400, auc=0.440\n",
      "  Subject s10177: acc=0.425, prec=0.412, f1=0.378, auc=0.382\n",
      "  Subject s10178: acc=0.615, prec=0.600, f1=0.643, auc=0.604\n",
      "  Subject s10180: acc=0.500, prec=0.500, f1=0.508, auc=0.440\n",
      "  Subject s10181: acc=0.470, prec=0.478, f1=0.557, auc=0.455\n",
      "  Subject s10183: acc=0.588, prec=0.615, f1=0.533, auc=0.567\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.125\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.629, auc=0.547\n",
      "  Subject s10188: acc=0.571, prec=0.571, f1=0.571, auc=0.509\n",
      "  Subject s10192: acc=0.530, prec=0.529, f1=0.537, auc=0.517\n",
      "  Subject s10195: acc=0.530, prec=0.526, f1=0.563, auc=0.562\n",
      "  Subject s10196: acc=0.600, prec=0.600, f1=0.600, auc=0.540\n",
      "  Subject s10197: acc=0.444, prec=0.444, f1=0.444, auc=0.457\n",
      "  Subject s10200: acc=0.460, prec=0.462, f1=0.471, auc=0.464\n",
      "  Subject s10202: acc=0.417, prec=0.400, f1=0.364, auc=0.472\n",
      "Mean over subjects — acc=0.481, prec=0.495, f1=0.478, auc=0.481\n",
      "\n",
      "=== Model: mlp ===\n",
      "  Subject s10014: acc=0.500, prec=0.500, f1=0.649, auc=0.479\n",
      "  Subject s10052: acc=0.500, prec=0.500, f1=0.118, auc=0.387\n",
      "  Subject s10059: acc=0.643, prec=0.667, f1=0.615, auc=0.653\n",
      "  Subject s10073: acc=0.607, prec=0.571, f1=0.686, auc=0.569\n",
      "  Subject s10081: acc=0.583, prec=0.600, f1=0.545, auc=0.694\n",
      "  Subject s10084: acc=0.500, prec=0.500, f1=0.364, auc=0.571\n",
      "  Subject s10085: acc=0.481, prec=0.476, f1=0.426, auc=0.473\n",
      "  Subject s10089: acc=0.545, prec=0.667, f1=0.286, auc=0.760\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.667, auc=0.500\n",
      "  Subject s10100: acc=0.468, prec=0.477, f1=0.560, auc=0.324\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.588, auc=0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10110: acc=0.594, prec=1.000, f1=0.316, auc=0.645\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.667, auc=0.405\n",
      "  Subject s10115: acc=0.589, prec=0.586, f1=0.596, auc=0.506\n",
      "  Subject s10117: acc=0.477, prec=0.476, f1=0.465, auc=0.461\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.667, auc=0.423\n",
      "  Subject s10125: acc=0.625, prec=0.714, f1=0.526, auc=0.707\n",
      "  Subject s10138: acc=0.444, prec=0.444, f1=0.444, auc=0.414\n",
      "  Subject s10139: acc=0.639, prec=0.667, f1=0.606, auc=0.741\n",
      "  Subject s10141: acc=0.679, prec=0.632, f1=0.727, auc=0.663\n",
      "  Subject s10144: acc=0.714, prec=0.667, f1=0.750, auc=0.673\n",
      "  Subject s10145: acc=0.556, prec=0.579, f1=0.478, auc=0.580\n",
      "  Subject s10148: acc=0.529, prec=0.520, f1=0.619, auc=0.606\n",
      "  Subject s10153: acc=0.435, prec=0.455, f1=0.536, auc=0.522\n",
      "  Subject s10156: acc=0.532, prec=0.524, f1=0.603, auc=0.569\n",
      "  Subject s10158: acc=0.438, prec=0.463, f1=0.581, auc=0.525\n",
      "  Subject s10159: acc=0.533, prec=0.556, f1=0.417, auc=0.601\n",
      "  Subject s10160: acc=0.500, prec=0.500, f1=0.480, auc=0.491\n",
      "  Subject s10165: acc=0.526, prec=0.667, f1=0.182, auc=0.499\n",
      "  Subject s10173: acc=0.600, prec=0.571, f1=0.667, auc=0.760\n",
      "  Subject s10177: acc=0.550, prec=1.000, f1=0.182, auc=0.542\n",
      "  Subject s10178: acc=0.500, prec=0.500, f1=0.519, auc=0.568\n",
      "  Subject s10180: acc=0.532, prec=0.533, f1=0.525, auc=0.590\n",
      "  Subject s10181: acc=0.515, prec=0.509, f1=0.628, auc=0.590\n",
      "  Subject s10183: acc=0.529, prec=0.515, f1=0.680, auc=0.754\n",
      "  Subject s10185: acc=0.500, prec=0.500, f1=0.667, auc=0.250\n",
      "  Subject s10186: acc=0.577, prec=0.545, f1=0.686, auc=0.627\n",
      "  Subject s10188: acc=0.571, prec=0.556, f1=0.625, auc=0.617\n",
      "  Subject s10192: acc=0.591, prec=0.556, f1=0.690, auc=0.647\n",
      "  Subject s10195: acc=0.591, prec=0.650, f1=0.491, auc=0.555\n",
      "  Subject s10196: acc=0.700, prec=0.750, f1=0.667, auc=0.800\n",
      "  Subject s10197: acc=0.611, prec=0.562, f1=0.720, auc=0.864\n",
      "  Subject s10200: acc=0.560, prec=0.800, f1=0.267, auc=0.720\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.250, auc=0.444\n",
      "Mean over subjects — acc=0.547, prec=0.579, f1=0.532, auc=0.576\n",
      "\n",
      "========== Feature set: EEG ==========\n",
      "\n",
      "=== Model: logreg ===\n",
      "  Subject s10014: acc=0.538, prec=0.524, f1=0.647, auc=0.491\n",
      "  Subject s10052: acc=0.533, prec=0.533, f1=0.533, auc=0.569\n",
      "  Subject s10059: acc=0.429, prec=0.400, f1=0.333, auc=0.388\n",
      "  Subject s10073: acc=0.536, prec=0.519, f1=0.683, auc=0.577\n",
      "  Subject s10081: acc=0.479, prec=0.471, f1=0.390, auc=0.490\n",
      "  Subject s10084: acc=0.500, prec=0.500, f1=0.160, auc=0.476\n",
      "  Subject s10085: acc=0.462, prec=0.462, f1=0.462, auc=0.527\n",
      "  Subject s10089: acc=0.500, prec=0.500, f1=0.522, auc=0.529\n",
      "  Subject s10094: acc=0.750, prec=0.667, f1=0.800, auc=0.500\n",
      "  Subject s10100: acc=0.565, prec=0.643, f1=0.400, auc=0.601\n",
      "  Subject s10103: acc=0.357, prec=0.400, f1=0.471, auc=0.347\n",
      "  Subject s10110: acc=0.594, prec=0.714, f1=0.435, auc=0.609\n",
      "  Subject s10111: acc=0.484, prec=0.491, f1=0.628, auc=0.452\n",
      "  Subject s10115: acc=0.536, prec=0.536, f1=0.536, auc=0.533\n",
      "  Subject s10117: acc=0.523, prec=1.000, f1=0.087, auc=0.397\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.417, auc=0.454\n",
      "  Subject s10125: acc=0.542, prec=0.525, f1=0.656, auc=0.553\n",
      "  Subject s10138: acc=0.370, prec=0.360, f1=0.346, auc=0.346\n",
      "  Subject s10139: acc=0.500, prec=0.500, f1=0.591, auc=0.559\n",
      "  Subject s10141: acc=0.607, prec=0.588, f1=0.645, auc=0.556\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.667, auc=0.735\n",
      "  Subject s10145: acc=0.481, prec=0.488, f1=0.588, auc=0.491\n",
      "  Subject s10148: acc=0.559, prec=0.536, f1=0.667, auc=0.612\n",
      "  Subject s10153: acc=0.478, prec=0.471, f1=0.400, auc=0.408\n",
      "  Subject s10156: acc=0.500, prec=0.500, f1=0.061, auc=0.440\n",
      "  Subject s10158: acc=0.438, prec=0.417, f1=0.357, auc=0.419\n",
      "  Subject s10159: acc=0.533, prec=0.667, f1=0.222, auc=0.624\n",
      "  Subject s10160: acc=0.500, prec=0.000, f1=0.000, auc=0.260\n",
      "  Subject s10165: acc=0.526, prec=0.556, f1=0.357, auc=0.634\n",
      "  Subject s10173: acc=0.700, prec=0.625, f1=0.769, auc=0.800\n",
      "  Subject s10177: acc=0.500, prec=0.500, f1=0.667, auc=0.417\n",
      "  Subject s10178: acc=0.538, prec=1.000, f1=0.143, auc=0.509\n",
      "  Subject s10180: acc=0.419, prec=0.439, f1=0.500, auc=0.462\n",
      "  Subject s10181: acc=0.515, prec=0.509, f1=0.628, auc=0.572\n",
      "  Subject s10183: acc=0.441, prec=0.458, f1=0.537, auc=0.443\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.000\n",
      "  Subject s10186: acc=0.577, prec=0.542, f1=0.703, auc=0.391\n",
      "  Subject s10188: acc=0.548, prec=0.533, f1=0.627, auc=0.576\n",
      "  Subject s10192: acc=0.530, prec=0.531, f1=0.523, auc=0.541\n",
      "  Subject s10195: acc=0.515, prec=0.571, f1=0.200, auc=0.598\n",
      "  Subject s10196: acc=0.400, prec=0.400, f1=0.400, auc=0.360\n",
      "  Subject s10197: acc=0.556, prec=0.538, f1=0.636, auc=0.556\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.390, auc=0.510\n",
      "  Subject s10202: acc=0.583, prec=0.600, f1=0.545, auc=0.361\n",
      "Mean over subjects — acc=0.509, prec=0.524, f1=0.471, auc=0.493\n",
      "\n",
      "=== Model: linear_svc ===\n",
      "  Subject s10014: acc=0.538, prec=0.524, f1=0.647, auc=0.485\n",
      "  Subject s10052: acc=0.567, prec=0.562, f1=0.581, auc=0.573\n",
      "  Subject s10059: acc=0.500, prec=0.500, f1=0.364, auc=0.388\n",
      "  Subject s10073: acc=0.536, prec=0.519, f1=0.683, auc=0.561\n",
      "  Subject s10081: acc=0.500, prec=0.500, f1=0.400, auc=0.472\n",
      "  Subject s10084: acc=0.476, prec=0.400, f1=0.154, auc=0.474\n",
      "  Subject s10085: acc=0.500, prec=0.500, f1=0.519, auc=0.519\n",
      "  Subject s10089: acc=0.455, prec=0.455, f1=0.455, auc=0.537\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.500\n",
      "  Subject s10100: acc=0.565, prec=0.643, f1=0.400, auc=0.612\n",
      "  Subject s10103: acc=0.286, prec=0.364, f1=0.444, auc=0.347\n",
      "  Subject s10110: acc=0.594, prec=0.714, f1=0.435, auc=0.617\n",
      "  Subject s10111: acc=0.484, prec=0.491, f1=0.628, auc=0.453\n",
      "  Subject s10115: acc=0.536, prec=0.536, f1=0.536, auc=0.541\n",
      "  Subject s10117: acc=0.545, prec=1.000, f1=0.167, auc=0.411\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.417, auc=0.434\n",
      "  Subject s10125: acc=0.562, prec=0.541, f1=0.656, auc=0.549\n",
      "  Subject s10138: acc=0.370, prec=0.348, f1=0.320, auc=0.354\n",
      "  Subject s10139: acc=0.500, prec=0.500, f1=0.591, auc=0.574\n",
      "  Subject s10141: acc=0.607, prec=0.588, f1=0.645, auc=0.546\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.667, auc=0.735\n",
      "  Subject s10145: acc=0.500, prec=0.500, f1=0.597, auc=0.502\n",
      "  Subject s10148: acc=0.559, prec=0.536, f1=0.667, auc=0.626\n",
      "  Subject s10153: acc=0.478, prec=0.471, f1=0.400, auc=0.418\n",
      "  Subject s10156: acc=0.500, prec=0.500, f1=0.061, auc=0.438\n",
      "  Subject s10158: acc=0.453, prec=0.435, f1=0.364, auc=0.421\n",
      "  Subject s10159: acc=0.533, prec=0.667, f1=0.222, auc=0.629\n",
      "  Subject s10160: acc=0.500, prec=0.000, f1=0.000, auc=0.278\n",
      "  Subject s10165: acc=0.526, prec=0.556, f1=0.357, auc=0.645\n",
      "  Subject s10173: acc=0.700, prec=0.625, f1=0.769, auc=0.760\n",
      "  Subject s10177: acc=0.500, prec=0.500, f1=0.667, auc=0.433\n",
      "  Subject s10178: acc=0.538, prec=1.000, f1=0.143, auc=0.509\n",
      "  Subject s10180: acc=0.419, prec=0.439, f1=0.500, auc=0.465\n",
      "  Subject s10181: acc=0.500, prec=0.500, f1=0.621, auc=0.569\n",
      "  Subject s10183: acc=0.441, prec=0.458, f1=0.537, auc=0.436\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.000\n",
      "  Subject s10186: acc=0.538, prec=0.520, f1=0.684, auc=0.396\n",
      "  Subject s10188: acc=0.548, prec=0.538, f1=0.596, auc=0.571\n",
      "  Subject s10192: acc=0.530, prec=0.531, f1=0.523, auc=0.546\n",
      "  Subject s10195: acc=0.530, prec=0.600, f1=0.279, auc=0.587\n",
      "  Subject s10196: acc=0.400, prec=0.400, f1=0.400, auc=0.360\n",
      "  Subject s10197: acc=0.556, prec=0.538, f1=0.636, auc=0.556\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.390, auc=0.505\n",
      "  Subject s10202: acc=0.583, prec=0.600, f1=0.545, auc=0.361\n",
      "Mean over subjects — acc=0.505, prec=0.521, f1=0.467, auc=0.493\n",
      "\n",
      "=== Model: rbf_svc ===\n",
      "  Subject s10014: acc=0.558, prec=0.532, f1=0.685, auc=0.405\n",
      "  Subject s10052: acc=0.500, prec=0.500, f1=0.667, auc=0.551\n",
      "  Subject s10059: acc=0.500, prec=0.000, f1=0.000, auc=0.612\n",
      "  Subject s10073: acc=0.536, prec=0.519, f1=0.683, auc=0.291\n",
      "  Subject s10081: acc=0.458, prec=0.477, f1=0.618, auc=0.568\n",
      "  Subject s10084: acc=0.476, prec=0.474, f1=0.450, auc=0.559\n",
      "  Subject s10085: acc=0.462, prec=0.455, f1=0.417, auc=0.559\n",
      "  Subject s10089: acc=0.409, prec=0.333, f1=0.235, auc=0.504\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.667, auc=0.750\n",
      "  Subject s10100: acc=0.581, prec=0.857, f1=0.316, auc=0.397\n",
      "  Subject s10103: acc=0.429, prec=0.462, f1=0.600, auc=0.571\n",
      "  Subject s10110: acc=0.469, prec=0.462, f1=0.414, auc=0.486\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.667, auc=0.506\n",
      "  Subject s10115: acc=0.482, prec=0.333, f1=0.065, auc=0.642\n",
      "  Subject s10117: acc=0.500, prec=0.000, f1=0.000, auc=0.754\n",
      "  Subject s10121: acc=0.571, prec=0.750, f1=0.333, auc=0.487\n",
      "  Subject s10125: acc=0.500, prec=0.000, f1=0.000, auc=0.440\n",
      "  Subject s10138: acc=0.426, prec=0.400, f1=0.340, auc=0.584\n",
      "  Subject s10139: acc=0.528, prec=0.514, f1=0.679, auc=0.534\n",
      "  Subject s10141: acc=0.500, prec=0.000, f1=0.000, auc=0.383\n",
      "  Subject s10144: acc=0.500, prec=0.500, f1=0.667, auc=0.408\n",
      "  Subject s10145: acc=0.519, prec=0.519, f1=0.519, auc=0.433\n",
      "  Subject s10148: acc=0.471, prec=0.480, f1=0.571, auc=0.540\n",
      "  Subject s10153: acc=0.522, prec=0.533, f1=0.421, auc=0.406\n",
      "  Subject s10156: acc=0.500, prec=0.500, f1=0.205, auc=0.425\n",
      "  Subject s10158: acc=0.516, prec=0.533, f1=0.340, auc=0.487\n",
      "  Subject s10159: acc=0.533, prec=1.000, f1=0.125, auc=0.376\n",
      "  Subject s10160: acc=0.577, prec=0.750, f1=0.353, auc=0.302\n",
      "  Subject s10165: acc=0.579, prec=1.000, f1=0.273, auc=0.557\n",
      "  Subject s10173: acc=0.700, prec=0.625, f1=0.769, auc=0.400\n",
      "  Subject s10177: acc=0.450, prec=0.464, f1=0.542, auc=0.565\n",
      "  Subject s10178: acc=0.385, prec=0.286, f1=0.200, auc=0.598\n",
      "  Subject s10180: acc=0.484, prec=0.429, f1=0.158, auc=0.494\n",
      "  Subject s10181: acc=0.515, prec=0.512, f1=0.568, auc=0.425\n",
      "  Subject s10183: acc=0.471, prec=0.478, f1=0.550, auc=0.460\n",
      "  Subject s10185: acc=0.000, prec=0.000, f1=0.000, auc=1.000\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.581, auc=0.512\n",
      "  Subject s10188: acc=0.571, prec=0.636, f1=0.438, auc=0.481\n",
      "  Subject s10192: acc=0.561, prec=0.548, f1=0.613, auc=0.445\n",
      "  Subject s10195: acc=0.500, prec=0.500, f1=0.108, auc=0.417\n",
      "  Subject s10196: acc=0.200, prec=0.286, f1=0.333, auc=0.720\n",
      "  Subject s10197: acc=0.611, prec=0.562, f1=0.720, auc=0.383\n",
      "  Subject s10200: acc=0.540, prec=0.522, f1=0.676, auc=0.503\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.625, auc=0.583\n",
      "Mean over subjects — acc=0.491, prec=0.471, f1=0.413, auc=0.511\n",
      "\n",
      "=== Model: random_forest ===\n",
      "  Subject s10014: acc=0.519, prec=0.510, f1=0.667, auc=0.542\n",
      "  Subject s10052: acc=0.467, prec=0.480, f1=0.600, auc=0.449\n",
      "  Subject s10059: acc=0.500, prec=0.500, f1=0.364, auc=0.561\n",
      "  Subject s10073: acc=0.464, prec=0.476, f1=0.571, auc=0.651\n",
      "  Subject s10081: acc=0.458, prec=0.455, f1=0.435, auc=0.420\n",
      "  Subject s10084: acc=0.595, prec=0.600, f1=0.585, auc=0.584\n",
      "  Subject s10085: acc=0.577, prec=0.559, f1=0.633, auc=0.468\n",
      "  Subject s10089: acc=0.591, prec=0.583, f1=0.609, auc=0.587\n",
      "  Subject s10094: acc=0.750, prec=0.667, f1=0.800, auc=0.750\n",
      "  Subject s10100: acc=0.484, prec=0.489, f1=0.590, auc=0.519\n",
      "  Subject s10103: acc=0.643, prec=0.625, f1=0.667, auc=0.602\n",
      "  Subject s10110: acc=0.531, prec=0.533, f1=0.516, auc=0.496\n",
      "  Subject s10111: acc=0.452, prec=0.471, f1=0.585, auc=0.448\n",
      "  Subject s10115: acc=0.536, prec=0.525, f1=0.618, auc=0.476\n",
      "  Subject s10117: acc=0.432, prec=0.435, f1=0.444, auc=0.473\n",
      "  Subject s10121: acc=0.429, prec=0.450, f1=0.529, auc=0.520\n",
      "  Subject s10125: acc=0.542, prec=0.550, f1=0.500, auc=0.553\n",
      "  Subject s10138: acc=0.389, prec=0.412, f1=0.459, auc=0.414\n",
      "  Subject s10139: acc=0.556, prec=0.542, f1=0.619, auc=0.511\n",
      "  Subject s10141: acc=0.536, prec=0.538, f1=0.519, auc=0.597\n",
      "  Subject s10144: acc=0.643, prec=0.583, f1=0.737, auc=0.867\n",
      "  Subject s10145: acc=0.537, prec=0.525, f1=0.627, auc=0.481\n",
      "  Subject s10148: acc=0.618, prec=0.571, f1=0.711, auc=0.676\n",
      "  Subject s10153: acc=0.391, prec=0.414, f1=0.462, auc=0.336\n",
      "  Subject s10156: acc=0.516, prec=0.667, f1=0.118, auc=0.448\n",
      "  Subject s10158: acc=0.453, prec=0.435, f1=0.364, auc=0.525\n",
      "  Subject s10159: acc=0.533, prec=0.542, f1=0.481, auc=0.533\n",
      "  Subject s10160: acc=0.500, prec=0.500, f1=0.552, auc=0.565\n",
      "  Subject s10165: acc=0.474, prec=0.480, f1=0.545, auc=0.596\n",
      "  Subject s10173: acc=0.500, prec=0.500, f1=0.667, auc=0.600\n",
      "  Subject s10177: acc=0.475, prec=0.483, f1=0.571, auc=0.420\n",
      "  Subject s10178: acc=0.462, prec=0.455, f1=0.417, auc=0.470\n",
      "  Subject s10180: acc=0.565, prec=0.548, f1=0.630, auc=0.641\n",
      "  Subject s10181: acc=0.530, prec=0.521, f1=0.617, auc=0.556\n",
      "  Subject s10183: acc=0.382, prec=0.423, f1=0.512, auc=0.512\n",
      "  Subject s10185: acc=0.500, prec=0.500, f1=0.500, auc=0.250\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.649, auc=0.361\n",
      "  Subject s10188: acc=0.619, prec=0.667, f1=0.556, auc=0.630\n",
      "  Subject s10192: acc=0.530, prec=0.522, f1=0.608, auc=0.546\n",
      "  Subject s10195: acc=0.455, prec=0.467, f1=0.538, auc=0.416\n",
      "  Subject s10196: acc=0.400, prec=0.400, f1=0.400, auc=0.440\n",
      "  Subject s10197: acc=0.500, prec=0.500, f1=0.667, auc=0.747\n",
      "  Subject s10200: acc=0.460, prec=0.476, f1=0.597, auc=0.463\n",
      "  Subject s10202: acc=0.417, prec=0.444, f1=0.533, auc=0.333\n",
      "Mean over subjects — acc=0.509, prec=0.512, f1=0.554, auc=0.524\n",
      "\n",
      "=== Model: gradient_boosting ===\n",
      "  Subject s10014: acc=0.558, prec=0.537, f1=0.657, auc=0.578\n",
      "  Subject s10052: acc=0.500, prec=0.500, f1=0.516, auc=0.444\n",
      "  Subject s10059: acc=0.429, prec=0.455, f1=0.556, auc=0.408\n",
      "  Subject s10073: acc=0.607, prec=0.571, f1=0.686, auc=0.411\n",
      "  Subject s10081: acc=0.438, prec=0.412, f1=0.341, auc=0.328\n",
      "  Subject s10084: acc=0.357, prec=0.364, f1=0.372, auc=0.385\n",
      "  Subject s10085: acc=0.577, prec=0.611, f1=0.500, auc=0.602\n",
      "  Subject s10089: acc=0.409, prec=0.438, f1=0.519, auc=0.298\n",
      "  Subject s10094: acc=0.750, prec=0.667, f1=0.800, auc=0.625\n",
      "  Subject s10100: acc=0.516, prec=0.520, f1=0.464, auc=0.499\n",
      "  Subject s10103: acc=0.429, prec=0.455, f1=0.556, auc=0.449\n",
      "  Subject s10110: acc=0.312, prec=0.125, f1=0.083, auc=0.283\n",
      "  Subject s10111: acc=0.516, prec=0.508, f1=0.667, auc=0.358\n",
      "  Subject s10115: acc=0.411, prec=0.439, f1=0.522, auc=0.444\n",
      "  Subject s10117: acc=0.545, prec=0.533, f1=0.615, auc=0.473\n",
      "  Subject s10121: acc=0.429, prec=0.400, f1=0.333, auc=0.390\n",
      "  Subject s10125: acc=0.438, prec=0.452, f1=0.509, auc=0.475\n",
      "  Subject s10138: acc=0.352, prec=0.346, f1=0.340, auc=0.401\n",
      "  Subject s10139: acc=0.611, prec=0.643, f1=0.562, auc=0.642\n",
      "  Subject s10141: acc=0.500, prec=0.500, f1=0.417, auc=0.472\n",
      "  Subject s10144: acc=0.429, prec=0.462, f1=0.600, auc=0.602\n",
      "  Subject s10145: acc=0.537, prec=0.531, f1=0.576, auc=0.595\n",
      "  Subject s10148: acc=0.529, prec=0.538, f1=0.467, auc=0.554\n",
      "  Subject s10153: acc=0.522, prec=0.519, f1=0.560, auc=0.505\n",
      "  Subject s10156: acc=0.548, prec=0.615, f1=0.364, auc=0.592\n",
      "  Subject s10158: acc=0.484, prec=0.455, f1=0.233, auc=0.540\n",
      "  Subject s10159: acc=0.500, prec=0.500, f1=0.444, auc=0.531\n",
      "  Subject s10160: acc=0.462, prec=0.429, f1=0.300, auc=0.547\n",
      "  Subject s10165: acc=0.526, prec=0.538, f1=0.438, auc=0.501\n",
      "  Subject s10173: acc=0.600, prec=0.571, f1=0.667, auc=0.660\n",
      "  Subject s10177: acc=0.400, prec=0.409, f1=0.429, auc=0.346\n",
      "  Subject s10178: acc=0.423, prec=0.375, f1=0.286, auc=0.402\n",
      "  Subject s10180: acc=0.532, prec=0.531, f1=0.540, auc=0.550\n",
      "  Subject s10181: acc=0.530, prec=0.524, f1=0.587, auc=0.577\n",
      "  Subject s10183: acc=0.412, prec=0.440, f1=0.524, auc=0.353\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.000\n",
      "  Subject s10186: acc=0.423, prec=0.450, f1=0.545, auc=0.396\n",
      "  Subject s10188: acc=0.500, prec=0.500, f1=0.553, auc=0.495\n",
      "  Subject s10192: acc=0.515, prec=0.512, f1=0.568, auc=0.565\n",
      "  Subject s10195: acc=0.576, prec=0.568, f1=0.600, auc=0.534\n",
      "  Subject s10196: acc=0.600, prec=0.667, f1=0.500, auc=0.560\n",
      "  Subject s10197: acc=0.444, prec=0.471, f1=0.615, auc=0.469\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.561, auc=0.474\n",
      "  Subject s10202: acc=0.250, prec=0.286, f1=0.308, auc=0.167\n",
      "Mean over subjects — acc=0.481, prec=0.482, f1=0.493, auc=0.466\n",
      "\n",
      "=== Model: knn ===\n",
      "  Subject s10014: acc=0.500, prec=0.500, f1=0.552, auc=0.489\n",
      "  Subject s10052: acc=0.300, prec=0.286, f1=0.276, auc=0.244\n",
      "  Subject s10059: acc=0.500, prec=0.500, f1=0.462, auc=0.582\n",
      "  Subject s10073: acc=0.643, prec=0.625, f1=0.667, auc=0.663\n",
      "  Subject s10081: acc=0.604, prec=0.576, f1=0.667, auc=0.582\n",
      "  Subject s10084: acc=0.548, prec=0.545, f1=0.558, auc=0.506\n",
      "  Subject s10085: acc=0.423, prec=0.417, f1=0.400, auc=0.392\n",
      "  Subject s10089: acc=0.318, prec=0.375, f1=0.444, auc=0.326\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.667, auc=0.500\n",
      "  Subject s10100: acc=0.500, prec=0.500, f1=0.508, auc=0.490\n",
      "  Subject s10103: acc=0.429, prec=0.429, f1=0.429, auc=0.561\n",
      "  Subject s10110: acc=0.406, prec=0.364, f1=0.296, auc=0.434\n",
      "  Subject s10111: acc=0.452, prec=0.463, f1=0.528, auc=0.476\n",
      "  Subject s10115: acc=0.446, prec=0.455, f1=0.492, auc=0.400\n",
      "  Subject s10117: acc=0.432, prec=0.429, f1=0.419, auc=0.430\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.533, auc=0.541\n",
      "  Subject s10125: acc=0.479, prec=0.333, f1=0.074, auc=0.460\n",
      "  Subject s10138: acc=0.611, prec=0.607, f1=0.618, auc=0.588\n",
      "  Subject s10139: acc=0.556, prec=0.533, f1=0.667, auc=0.535\n",
      "  Subject s10141: acc=0.429, prec=0.400, f1=0.333, auc=0.429\n",
      "  Subject s10144: acc=0.357, prec=0.400, f1=0.471, auc=0.490\n",
      "  Subject s10145: acc=0.407, prec=0.381, f1=0.333, auc=0.460\n",
      "  Subject s10148: acc=0.500, prec=0.500, f1=0.622, auc=0.457\n",
      "  Subject s10153: acc=0.413, prec=0.423, f1=0.449, auc=0.387\n",
      "  Subject s10156: acc=0.548, prec=0.579, f1=0.440, auc=0.538\n",
      "  Subject s10158: acc=0.375, prec=0.367, f1=0.355, auc=0.380\n",
      "  Subject s10159: acc=0.567, prec=0.571, f1=0.552, auc=0.577\n",
      "  Subject s10160: acc=0.462, prec=0.474, f1=0.562, auc=0.432\n",
      "  Subject s10165: acc=0.526, prec=0.522, f1=0.571, auc=0.533\n",
      "  Subject s10173: acc=0.400, prec=0.400, f1=0.400, auc=0.380\n",
      "  Subject s10177: acc=0.425, prec=0.412, f1=0.378, auc=0.386\n",
      "  Subject s10178: acc=0.500, prec=0.500, f1=0.552, auc=0.527\n",
      "  Subject s10180: acc=0.548, prec=0.565, f1=0.481, auc=0.503\n",
      "  Subject s10181: acc=0.455, prec=0.467, f1=0.538, auc=0.414\n",
      "  Subject s10183: acc=0.588, prec=0.600, f1=0.562, auc=0.526\n",
      "  Subject s10185: acc=0.250, prec=0.333, f1=0.400, auc=0.125\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.629, auc=0.441\n",
      "  Subject s10188: acc=0.571, prec=0.579, f1=0.550, auc=0.567\n",
      "  Subject s10192: acc=0.470, prec=0.472, f1=0.493, auc=0.465\n",
      "  Subject s10195: acc=0.470, prec=0.475, f1=0.521, auc=0.466\n",
      "  Subject s10196: acc=0.600, prec=0.667, f1=0.500, auc=0.580\n",
      "  Subject s10197: acc=0.389, prec=0.400, f1=0.421, auc=0.395\n",
      "  Subject s10200: acc=0.420, prec=0.423, f1=0.431, auc=0.458\n",
      "  Subject s10202: acc=0.583, prec=0.556, f1=0.667, auc=0.417\n",
      "Mean over subjects — acc=0.475, prec=0.475, f1=0.488, auc=0.467\n",
      "\n",
      "=== Model: mlp ===\n",
      "  Subject s10014: acc=0.462, prec=0.477, f1=0.600, auc=0.481\n",
      "  Subject s10052: acc=0.467, prec=0.429, f1=0.273, auc=0.351\n",
      "  Subject s10059: acc=0.500, prec=0.000, f1=0.000, auc=0.388\n",
      "  Subject s10073: acc=0.643, prec=0.591, f1=0.722, auc=0.704\n",
      "  Subject s10081: acc=0.458, prec=0.444, f1=0.381, auc=0.450\n",
      "  Subject s10084: acc=0.500, prec=0.500, f1=0.462, auc=0.519\n",
      "  Subject s10085: acc=0.500, prec=0.500, f1=0.536, auc=0.459\n",
      "  Subject s10089: acc=0.591, prec=0.750, f1=0.400, auc=0.760\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.667, auc=0.250\n",
      "  Subject s10100: acc=0.500, prec=0.500, f1=0.608, auc=0.543\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.462, auc=0.490\n",
      "  Subject s10110: acc=0.562, prec=0.600, f1=0.462, auc=0.543\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.659, auc=0.493\n",
      "  Subject s10115: acc=0.446, prec=0.457, f1=0.508, auc=0.402\n",
      "  Subject s10117: acc=0.500, prec=0.500, f1=0.577, auc=0.488\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.632, auc=0.587\n",
      "  Subject s10125: acc=0.583, prec=0.700, f1=0.412, auc=0.577\n",
      "  Subject s10138: acc=0.389, prec=0.375, f1=0.353, auc=0.346\n",
      "  Subject s10139: acc=0.528, prec=0.522, f1=0.585, auc=0.506\n",
      "  Subject s10141: acc=0.500, prec=0.500, f1=0.222, auc=0.577\n",
      "  Subject s10144: acc=0.714, prec=0.667, f1=0.750, auc=0.755\n",
      "  Subject s10145: acc=0.611, prec=0.714, f1=0.488, auc=0.669\n",
      "  Subject s10148: acc=0.471, prec=0.467, f1=0.438, auc=0.415\n",
      "  Subject s10153: acc=0.391, prec=0.419, f1=0.481, auc=0.414\n",
      "  Subject s10156: acc=0.452, prec=0.429, f1=0.346, auc=0.467\n",
      "  Subject s10158: acc=0.484, prec=0.489, f1=0.571, auc=0.542\n",
      "  Subject s10159: acc=0.467, prec=0.417, f1=0.238, auc=0.526\n",
      "  Subject s10160: acc=0.500, prec=0.500, f1=0.606, auc=0.604\n",
      "  Subject s10165: acc=0.553, prec=0.538, f1=0.622, auc=0.537\n",
      "  Subject s10173: acc=0.300, prec=0.333, f1=0.364, auc=0.440\n",
      "  Subject s10177: acc=0.475, prec=0.444, f1=0.276, auc=0.570\n",
      "  Subject s10178: acc=0.462, prec=0.455, f1=0.417, auc=0.473\n",
      "  Subject s10180: acc=0.468, prec=0.438, f1=0.298, auc=0.487\n",
      "  Subject s10181: acc=0.470, prec=0.482, f1=0.607, auc=0.421\n",
      "  Subject s10183: acc=0.471, prec=0.474, f1=0.500, auc=0.512\n",
      "  Subject s10185: acc=0.000, prec=0.000, f1=0.000, auc=0.000\n",
      "  Subject s10186: acc=0.500, prec=0.500, f1=0.667, auc=0.432\n",
      "  Subject s10188: acc=0.452, prec=0.471, f1=0.582, auc=0.519\n",
      "  Subject s10192: acc=0.470, prec=0.481, f1=0.598, auc=0.517\n",
      "  Subject s10195: acc=0.621, prec=0.654, f1=0.576, auc=0.629\n",
      "  Subject s10196: acc=0.700, prec=0.750, f1=0.667, auc=0.720\n",
      "  Subject s10197: acc=0.556, prec=0.538, f1=0.636, auc=0.617\n",
      "  Subject s10200: acc=0.560, prec=0.615, f1=0.421, auc=0.657\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.250, auc=0.333\n",
      "Mean over subjects — acc=0.495, prec=0.491, f1=0.475, auc=0.504\n",
      "\n",
      "========== Feature set: Eye ==========\n",
      "\n",
      "=== Model: logreg ===\n",
      "  Subject s10014: acc=0.615, prec=0.714, f1=0.500, auc=0.593\n",
      "  Subject s10052: acc=0.533, prec=0.545, f1=0.462, auc=0.520\n",
      "  Subject s10059: acc=0.929, prec=0.875, f1=0.933, auc=0.898\n",
      "  Subject s10073: acc=0.714, prec=0.714, f1=0.714, auc=0.765\n",
      "  Subject s10081: acc=0.583, prec=0.700, f1=0.412, auc=0.743\n",
      "  Subject s10084: acc=0.714, prec=0.765, f1=0.684, auc=0.771\n",
      "  Subject s10085: acc=0.731, prec=0.875, f1=0.667, auc=0.834\n",
      "  Subject s10089: acc=0.591, prec=0.667, f1=0.471, auc=0.669\n",
      "  Subject s10094: acc=0.750, prec=1.000, f1=0.667, auc=0.750\n",
      "  Subject s10100: acc=0.468, prec=0.444, f1=0.327, auc=0.387\n",
      "  Subject s10103: acc=0.643, prec=0.583, f1=0.737, auc=0.735\n",
      "  Subject s10110: acc=0.562, prec=0.562, f1=0.562, auc=0.570\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.617, auc=0.527\n",
      "  Subject s10115: acc=0.571, prec=0.559, f1=0.613, auc=0.634\n",
      "  Subject s10117: acc=0.614, prec=0.619, f1=0.605, auc=0.643\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.611, auc=0.531\n",
      "  Subject s10125: acc=0.521, prec=0.511, f1=0.676, auc=0.724\n",
      "  Subject s10138: acc=0.574, prec=0.667, f1=0.410, auc=0.689\n",
      "  Subject s10139: acc=0.806, prec=0.762, f1=0.821, auc=0.883\n",
      "  Subject s10141: acc=0.643, prec=0.750, f1=0.545, auc=0.755\n",
      "  Subject s10144: acc=0.714, prec=0.800, f1=0.667, auc=0.796\n",
      "  Subject s10145: acc=0.593, prec=0.727, f1=0.421, auc=0.683\n",
      "  Subject s10148: acc=0.588, prec=0.571, f1=0.632, auc=0.727\n",
      "  Subject s10153: acc=0.522, prec=0.520, f1=0.542, auc=0.548\n",
      "  Subject s10156: acc=0.790, prec=0.765, f1=0.800, auc=0.893\n",
      "  Subject s10158: acc=0.688, prec=0.625, f1=0.750, auc=0.807\n",
      "  Subject s10159: acc=0.517, prec=0.600, f1=0.171, auc=0.744\n",
      "  Subject s10160: acc=0.654, prec=0.643, f1=0.667, auc=0.716\n",
      "  Subject s10165: acc=0.500, prec=0.000, f1=0.000, auc=0.310\n",
      "  Subject s10173: acc=0.800, prec=1.000, f1=0.750, auc=0.720\n",
      "  Subject s10177: acc=0.550, prec=0.583, f1=0.438, auc=0.585\n",
      "  Subject s10178: acc=0.577, prec=0.750, f1=0.353, auc=0.657\n",
      "  Subject s10180: acc=0.758, prec=0.735, f1=0.769, auc=0.799\n",
      "  Subject s10181: acc=0.561, prec=0.545, f1=0.623, auc=0.514\n",
      "  Subject s10183: acc=0.559, prec=0.531, f1=0.694, auc=0.706\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=1.000\n",
      "  Subject s10186: acc=0.615, prec=0.571, f1=0.706, auc=0.757\n",
      "  Subject s10188: acc=0.524, prec=0.514, f1=0.643, auc=0.560\n",
      "  Subject s10192: acc=0.591, prec=0.562, f1=0.667, auc=0.729\n",
      "  Subject s10195: acc=0.545, prec=0.537, f1=0.595, auc=0.584\n",
      "  Subject s10196: acc=0.900, prec=0.833, f1=0.909, auc=0.920\n",
      "  Subject s10197: acc=0.722, prec=0.700, f1=0.737, auc=0.815\n",
      "  Subject s10200: acc=0.460, prec=0.417, f1=0.270, auc=0.549\n",
      "  Subject s10202: acc=0.583, prec=0.667, f1=0.444, auc=0.667\n",
      "Mean over subjects — acc=0.628, prec=0.640, f1=0.593, auc=0.691\n",
      "\n",
      "=== Model: linear_svc ===\n",
      "  Subject s10014: acc=0.615, prec=0.714, f1=0.500, auc=0.599\n",
      "  Subject s10052: acc=0.533, prec=0.545, f1=0.462, auc=0.529\n",
      "  Subject s10059: acc=0.929, prec=0.875, f1=0.933, auc=0.898\n",
      "  Subject s10073: acc=0.714, prec=0.714, f1=0.714, auc=0.765\n",
      "  Subject s10081: acc=0.583, prec=0.700, f1=0.412, auc=0.743\n",
      "  Subject s10084: acc=0.714, prec=0.765, f1=0.684, auc=0.776\n",
      "  Subject s10085: acc=0.731, prec=0.875, f1=0.667, auc=0.834\n",
      "  Subject s10089: acc=0.636, prec=0.714, f1=0.556, auc=0.669\n",
      "  Subject s10094: acc=0.750, prec=1.000, f1=0.667, auc=0.750\n",
      "  Subject s10100: acc=0.484, prec=0.471, f1=0.333, auc=0.398\n",
      "  Subject s10103: acc=0.643, prec=0.583, f1=0.737, auc=0.735\n",
      "  Subject s10110: acc=0.562, prec=0.562, f1=0.562, auc=0.570\n",
      "  Subject s10111: acc=0.500, prec=0.500, f1=0.617, auc=0.528\n",
      "  Subject s10115: acc=0.571, prec=0.559, f1=0.613, auc=0.639\n",
      "  Subject s10117: acc=0.591, prec=0.591, f1=0.591, auc=0.640\n",
      "  Subject s10121: acc=0.500, prec=0.500, f1=0.611, auc=0.541\n",
      "  Subject s10125: acc=0.521, prec=0.511, f1=0.676, auc=0.726\n",
      "  Subject s10138: acc=0.574, prec=0.667, f1=0.410, auc=0.684\n",
      "  Subject s10139: acc=0.778, prec=0.727, f1=0.800, auc=0.883\n",
      "  Subject s10141: acc=0.643, prec=0.750, f1=0.545, auc=0.755\n",
      "  Subject s10144: acc=0.714, prec=0.800, f1=0.667, auc=0.796\n",
      "  Subject s10145: acc=0.574, prec=0.700, f1=0.378, auc=0.690\n",
      "  Subject s10148: acc=0.588, prec=0.571, f1=0.632, auc=0.723\n",
      "  Subject s10153: acc=0.522, prec=0.520, f1=0.542, auc=0.548\n",
      "  Subject s10156: acc=0.790, prec=0.765, f1=0.800, auc=0.893\n",
      "  Subject s10158: acc=0.688, prec=0.625, f1=0.750, auc=0.807\n",
      "  Subject s10159: acc=0.517, prec=0.600, f1=0.171, auc=0.741\n",
      "  Subject s10160: acc=0.654, prec=0.643, f1=0.667, auc=0.722\n",
      "  Subject s10165: acc=0.500, prec=0.000, f1=0.000, auc=0.310\n",
      "  Subject s10173: acc=0.800, prec=1.000, f1=0.750, auc=0.720\n",
      "  Subject s10177: acc=0.550, prec=0.583, f1=0.438, auc=0.585\n",
      "  Subject s10178: acc=0.577, prec=0.750, f1=0.353, auc=0.651\n",
      "  Subject s10180: acc=0.774, prec=0.743, f1=0.788, auc=0.800\n",
      "  Subject s10181: acc=0.545, prec=0.535, f1=0.605, auc=0.515\n",
      "  Subject s10183: acc=0.559, prec=0.531, f1=0.694, auc=0.706\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=1.000\n",
      "  Subject s10186: acc=0.615, prec=0.571, f1=0.706, auc=0.757\n",
      "  Subject s10188: acc=0.524, prec=0.514, f1=0.643, auc=0.556\n",
      "  Subject s10192: acc=0.606, prec=0.571, f1=0.683, auc=0.731\n",
      "  Subject s10195: acc=0.530, prec=0.524, f1=0.587, auc=0.578\n",
      "  Subject s10196: acc=0.800, prec=0.800, f1=0.800, auc=0.920\n",
      "  Subject s10197: acc=0.722, prec=0.700, f1=0.737, auc=0.815\n",
      "  Subject s10200: acc=0.460, prec=0.417, f1=0.270, auc=0.550\n",
      "  Subject s10202: acc=0.583, prec=0.667, f1=0.444, auc=0.694\n",
      "Mean over subjects — acc=0.625, prec=0.639, f1=0.591, auc=0.693\n",
      "\n",
      "=== Model: rbf_svc ===\n",
      "  Subject s10014: acc=0.481, prec=0.455, f1=0.270, auc=0.482\n",
      "  Subject s10052: acc=0.533, prec=0.571, f1=0.364, auc=0.631\n",
      "  Subject s10059: acc=0.714, prec=0.714, f1=0.714, auc=0.837\n",
      "  Subject s10073: acc=0.750, prec=0.769, f1=0.741, auc=0.811\n",
      "  Subject s10081: acc=0.667, prec=0.833, f1=0.556, auc=0.740\n",
      "  Subject s10084: acc=0.595, prec=0.611, f1=0.564, auc=0.680\n",
      "  Subject s10085: acc=0.654, prec=0.750, f1=0.571, auc=0.731\n",
      "  Subject s10089: acc=0.545, prec=0.556, f1=0.500, auc=0.636\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.750\n",
      "  Subject s10100: acc=0.516, prec=0.533, f1=0.348, auc=0.503\n",
      "  Subject s10103: acc=0.643, prec=0.600, f1=0.706, auc=0.592\n",
      "  Subject s10110: acc=0.531, prec=0.533, f1=0.516, auc=0.523\n",
      "  Subject s10111: acc=0.677, prec=0.617, f1=0.744, auc=0.663\n",
      "  Subject s10115: acc=0.589, prec=0.576, f1=0.623, auc=0.594\n",
      "  Subject s10117: acc=0.432, prec=0.412, f1=0.359, auc=0.475\n",
      "  Subject s10121: acc=0.571, prec=0.545, f1=0.667, auc=0.628\n",
      "  Subject s10125: acc=0.521, prec=0.511, f1=0.667, auc=0.557\n",
      "  Subject s10138: acc=0.537, prec=0.600, f1=0.324, auc=0.641\n",
      "  Subject s10139: acc=0.861, prec=0.810, f1=0.872, auc=0.920\n",
      "  Subject s10141: acc=0.643, prec=0.750, f1=0.545, auc=0.673\n",
      "  Subject s10144: acc=0.643, prec=0.667, f1=0.615, auc=0.776\n",
      "  Subject s10145: acc=0.519, prec=0.556, f1=0.278, auc=0.580\n",
      "  Subject s10148: acc=0.706, prec=0.733, f1=0.688, auc=0.744\n",
      "  Subject s10153: acc=0.478, prec=0.467, f1=0.368, auc=0.518\n",
      "  Subject s10156: acc=0.823, prec=0.812, f1=0.825, auc=0.864\n",
      "  Subject s10158: acc=0.703, prec=0.638, f1=0.759, auc=0.755\n",
      "  Subject s10159: acc=0.517, prec=0.571, f1=0.216, auc=0.717\n",
      "  Subject s10160: acc=0.769, prec=0.769, f1=0.769, auc=0.805\n",
      "  Subject s10165: acc=0.500, prec=0.500, f1=0.095, auc=0.681\n",
      "  Subject s10173: acc=0.600, prec=1.000, f1=0.333, auc=0.680\n",
      "  Subject s10177: acc=0.625, prec=0.778, f1=0.483, auc=0.600\n",
      "  Subject s10178: acc=0.615, prec=0.714, f1=0.500, auc=0.751\n",
      "  Subject s10180: acc=0.758, prec=0.722, f1=0.776, auc=0.773\n",
      "  Subject s10181: acc=0.500, prec=0.500, f1=0.548, auc=0.537\n",
      "  Subject s10183: acc=0.529, prec=0.515, f1=0.680, auc=0.727\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=0.750\n",
      "  Subject s10186: acc=0.769, prec=0.706, f1=0.800, auc=0.822\n",
      "  Subject s10188: acc=0.571, prec=0.552, f1=0.640, auc=0.642\n",
      "  Subject s10192: acc=0.636, prec=0.592, f1=0.707, auc=0.725\n",
      "  Subject s10195: acc=0.576, prec=0.571, f1=0.588, auc=0.592\n",
      "  Subject s10196: acc=0.900, prec=0.833, f1=0.909, auc=1.000\n",
      "  Subject s10197: acc=0.722, prec=0.667, f1=0.762, auc=0.778\n",
      "  Subject s10200: acc=0.560, prec=0.588, f1=0.476, auc=0.652\n",
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.400, auc=0.583\n",
      "Mean over subjects — acc=0.619, prec=0.633, f1=0.572, auc=0.684\n",
      "\n",
      "=== Model: random_forest ===\n",
      "  Subject s10014: acc=0.538, prec=0.562, f1=0.429, auc=0.505\n",
      "  Subject s10052: acc=0.567, prec=0.562, f1=0.581, auc=0.624\n",
      "  Subject s10059: acc=0.786, prec=0.833, f1=0.769, auc=0.878\n",
      "  Subject s10073: acc=0.750, prec=0.769, f1=0.741, auc=0.844\n",
      "  Subject s10081: acc=0.625, prec=0.750, f1=0.500, auc=0.697\n",
      "  Subject s10084: acc=0.619, prec=0.632, f1=0.600, auc=0.676\n",
      "  Subject s10085: acc=0.692, prec=0.812, f1=0.619, auc=0.749\n",
      "  Subject s10089: acc=0.455, prec=0.429, f1=0.333, auc=0.591\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.750\n",
      "  Subject s10100: acc=0.452, prec=0.421, f1=0.320, auc=0.390\n",
      "  Subject s10103: acc=0.571, prec=0.545, f1=0.667, auc=0.612\n",
      "  Subject s10110: acc=0.500, prec=0.500, f1=0.500, auc=0.439\n",
      "  Subject s10111: acc=0.613, prec=0.574, f1=0.692, auc=0.638\n",
      "  Subject s10115: acc=0.482, prec=0.486, f1=0.540, auc=0.492\n",
      "  Subject s10117: acc=0.364, prec=0.286, f1=0.222, auc=0.377\n",
      "  Subject s10121: acc=0.607, prec=0.571, f1=0.686, auc=0.653\n",
      "  Subject s10125: acc=0.521, prec=0.512, f1=0.657, auc=0.653\n",
      "  Subject s10138: acc=0.556, prec=0.571, f1=0.500, auc=0.617\n",
      "  Subject s10139: acc=0.806, prec=0.824, f1=0.800, auc=0.866\n",
      "  Subject s10141: acc=0.714, prec=0.800, f1=0.667, auc=0.750\n",
      "  Subject s10144: acc=0.714, prec=0.714, f1=0.714, auc=0.776\n",
      "  Subject s10145: acc=0.463, prec=0.417, f1=0.256, auc=0.494\n",
      "  Subject s10148: acc=0.471, prec=0.471, f1=0.471, auc=0.458\n",
      "  Subject s10153: acc=0.478, prec=0.471, f1=0.400, auc=0.467\n",
      "  Subject s10156: acc=0.710, prec=0.697, f1=0.719, auc=0.820\n",
      "  Subject s10158: acc=0.547, prec=0.538, f1=0.592, auc=0.591\n",
      "  Subject s10159: acc=0.500, prec=0.500, f1=0.286, auc=0.629\n",
      "  Subject s10160: acc=0.654, prec=0.625, f1=0.690, auc=0.639\n",
      "  Subject s10165: acc=0.553, prec=1.000, f1=0.190, auc=0.769\n",
      "  Subject s10173: acc=0.900, prec=1.000, f1=0.889, auc=0.800\n",
      "  Subject s10177: acc=0.525, prec=0.556, f1=0.345, auc=0.525\n",
      "  Subject s10178: acc=0.462, prec=0.429, f1=0.300, auc=0.556\n",
      "  Subject s10180: acc=0.613, prec=0.574, f1=0.692, auc=0.720\n",
      "  Subject s10181: acc=0.515, prec=0.511, f1=0.590, auc=0.572\n",
      "  Subject s10183: acc=0.500, prec=0.500, f1=0.653, auc=0.758\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=1.000\n",
      "  Subject s10186: acc=0.731, prec=0.650, f1=0.788, auc=0.861\n",
      "  Subject s10188: acc=0.500, prec=0.500, f1=0.604, auc=0.607\n",
      "  Subject s10192: acc=0.621, prec=0.595, f1=0.667, auc=0.706\n",
      "  Subject s10195: acc=0.485, prec=0.486, f1=0.514, auc=0.538\n",
      "  Subject s10196: acc=0.800, prec=0.800, f1=0.800, auc=0.940\n",
      "  Subject s10197: acc=0.667, prec=0.714, f1=0.625, auc=0.679\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.468, auc=0.562\n",
      "  Subject s10202: acc=0.417, prec=0.400, f1=0.364, auc=0.569\n",
      "Mean over subjects — acc=0.586, prec=0.597, f1=0.562, auc=0.655\n",
      "\n",
      "=== Model: gradient_boosting ===\n",
      "  Subject s10014: acc=0.519, prec=0.533, f1=0.390, auc=0.500\n",
      "  Subject s10052: acc=0.533, prec=0.538, f1=0.500, auc=0.516\n",
      "  Subject s10059: acc=0.857, prec=0.857, f1=0.857, auc=0.959\n",
      "  Subject s10073: acc=0.750, prec=0.769, f1=0.741, auc=0.842\n",
      "  Subject s10081: acc=0.604, prec=0.692, f1=0.486, auc=0.707\n",
      "  Subject s10084: acc=0.690, prec=0.722, f1=0.667, auc=0.769\n",
      "  Subject s10085: acc=0.635, prec=0.706, f1=0.558, auc=0.749\n",
      "  Subject s10089: acc=0.591, prec=0.625, f1=0.526, auc=0.612\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.750\n",
      "  Subject s10100: acc=0.500, prec=0.500, f1=0.367, auc=0.422\n",
      "  Subject s10103: acc=0.500, prec=0.500, f1=0.588, auc=0.469\n",
      "  Subject s10110: acc=0.500, prec=0.500, f1=0.429, auc=0.477\n",
      "  Subject s10111: acc=0.548, prec=0.532, f1=0.641, auc=0.618\n",
      "  Subject s10115: acc=0.554, prec=0.543, f1=0.603, auc=0.574\n",
      "  Subject s10117: acc=0.523, prec=0.526, f1=0.488, auc=0.502\n",
      "  Subject s10121: acc=0.607, prec=0.600, f1=0.621, auc=0.607\n",
      "  Subject s10125: acc=0.500, prec=0.500, f1=0.657, auc=0.524\n",
      "  Subject s10138: acc=0.556, prec=0.615, f1=0.400, auc=0.595\n",
      "  Subject s10139: acc=0.833, prec=0.833, f1=0.833, auc=0.917\n",
      "  Subject s10141: acc=0.607, prec=0.714, f1=0.476, auc=0.602\n",
      "  Subject s10144: acc=0.643, prec=0.667, f1=0.615, auc=0.694\n",
      "  Subject s10145: acc=0.519, prec=0.545, f1=0.316, auc=0.479\n",
      "  Subject s10148: acc=0.529, prec=0.529, f1=0.529, auc=0.585\n",
      "  Subject s10153: acc=0.457, prec=0.450, f1=0.419, auc=0.493\n",
      "  Subject s10156: acc=0.790, prec=0.781, f1=0.794, auc=0.853\n",
      "  Subject s10158: acc=0.562, prec=0.543, f1=0.641, auc=0.544\n",
      "  Subject s10159: acc=0.500, prec=0.500, f1=0.211, auc=0.602\n",
      "  Subject s10160: acc=0.577, prec=0.556, f1=0.645, auc=0.657\n",
      "  Subject s10165: acc=0.579, prec=1.000, f1=0.273, auc=0.676\n",
      "  Subject s10173: acc=0.600, prec=0.667, f1=0.500, auc=0.760\n",
      "  Subject s10177: acc=0.550, prec=0.600, f1=0.400, auc=0.605\n",
      "  Subject s10178: acc=0.615, prec=0.714, f1=0.500, auc=0.698\n",
      "  Subject s10180: acc=0.629, prec=0.595, f1=0.685, auc=0.696\n",
      "  Subject s10181: acc=0.561, prec=0.545, f1=0.623, auc=0.637\n",
      "  Subject s10183: acc=0.529, prec=0.515, f1=0.680, auc=0.626\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=0.750\n",
      "  Subject s10186: acc=0.615, prec=0.571, f1=0.706, auc=0.799\n",
      "  Subject s10188: acc=0.500, prec=0.500, f1=0.588, auc=0.599\n",
      "  Subject s10192: acc=0.652, prec=0.639, f1=0.667, auc=0.708\n",
      "  Subject s10195: acc=0.530, prec=0.526, f1=0.563, auc=0.535\n",
      "  Subject s10196: acc=0.600, prec=0.571, f1=0.667, auc=0.840\n",
      "  Subject s10197: acc=0.556, prec=0.545, f1=0.600, auc=0.580\n",
      "  Subject s10200: acc=0.500, prec=0.500, f1=0.510, auc=0.558\n",
      "  Subject s10202: acc=0.417, prec=0.400, f1=0.364, auc=0.472\n",
      "Mean over subjects — acc=0.583, prec=0.601, f1=0.560, auc=0.640\n",
      "\n",
      "=== Model: knn ===\n",
      "  Subject s10014: acc=0.404, prec=0.407, f1=0.415, auc=0.428\n",
      "  Subject s10052: acc=0.633, prec=0.667, f1=0.593, auc=0.620\n",
      "  Subject s10059: acc=0.643, prec=0.600, f1=0.706, auc=0.694\n",
      "  Subject s10073: acc=0.714, prec=0.750, f1=0.692, auc=0.763\n",
      "  Subject s10081: acc=0.667, prec=0.722, f1=0.619, auc=0.727\n",
      "  Subject s10084: acc=0.643, prec=0.667, f1=0.615, auc=0.687\n",
      "  Subject s10085: acc=0.673, prec=0.765, f1=0.605, auc=0.763\n",
      "  Subject s10089: acc=0.591, prec=0.625, f1=0.526, auc=0.583\n",
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.750\n",
      "  Subject s10100: acc=0.500, prec=0.500, f1=0.436, auc=0.417\n",
      "  Subject s10103: acc=0.571, prec=0.545, f1=0.667, auc=0.724\n",
      "  Subject s10110: acc=0.562, prec=0.550, f1=0.611, auc=0.502\n",
      "  Subject s10111: acc=0.597, prec=0.565, f1=0.675, auc=0.696\n",
      "  Subject s10115: acc=0.429, prec=0.441, f1=0.484, auc=0.457\n",
      "  Subject s10117: acc=0.409, prec=0.400, f1=0.381, auc=0.398\n",
      "  Subject s10121: acc=0.536, prec=0.526, f1=0.606, auc=0.607\n",
      "  Subject s10125: acc=0.521, prec=0.512, f1=0.657, auc=0.591\n",
      "  Subject s10138: acc=0.741, prec=0.882, f1=0.682, auc=0.802\n",
      "  Subject s10139: acc=0.722, prec=0.722, f1=0.722, auc=0.765\n",
      "  Subject s10141: acc=0.536, prec=0.538, f1=0.519, auc=0.597\n",
      "  Subject s10144: acc=0.571, prec=0.571, f1=0.571, auc=0.551\n",
      "  Subject s10145: acc=0.463, prec=0.450, f1=0.383, auc=0.541\n",
      "  Subject s10148: acc=0.441, prec=0.444, f1=0.457, auc=0.467\n",
      "  Subject s10153: acc=0.565, prec=0.588, f1=0.500, auc=0.557\n",
      "  Subject s10156: acc=0.613, prec=0.606, f1=0.625, auc=0.691\n",
      "  Subject s10158: acc=0.578, prec=0.571, f1=0.597, auc=0.586\n",
      "  Subject s10159: acc=0.550, prec=0.565, f1=0.491, auc=0.554\n",
      "  Subject s10160: acc=0.654, prec=0.667, f1=0.640, auc=0.698\n",
      "  Subject s10165: acc=0.500, prec=0.500, f1=0.095, auc=0.479\n",
      "  Subject s10173: acc=0.700, prec=0.750, f1=0.667, auc=0.620\n",
      "  Subject s10177: acc=0.625, prec=0.667, f1=0.571, auc=0.652\n",
      "  Subject s10178: acc=0.462, prec=0.444, f1=0.364, auc=0.494\n",
      "  Subject s10180: acc=0.581, prec=0.568, f1=0.618, auc=0.620\n",
      "  Subject s10181: acc=0.530, prec=0.526, f1=0.563, auc=0.590\n",
      "  Subject s10183: acc=0.471, prec=0.483, f1=0.609, auc=0.607\n",
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=0.500\n",
      "  Subject s10186: acc=0.692, prec=0.647, f1=0.733, auc=0.754\n",
      "  Subject s10188: acc=0.571, prec=0.556, f1=0.625, auc=0.643\n",
      "  Subject s10192: acc=0.576, prec=0.551, f1=0.659, auc=0.622\n",
      "  Subject s10195: acc=0.530, prec=0.525, f1=0.575, auc=0.521\n",
      "  Subject s10196: acc=0.700, prec=0.625, f1=0.769, auc=0.720\n",
      "  Subject s10197: acc=0.389, prec=0.400, f1=0.421, auc=0.370\n",
      "  Subject s10200: acc=0.540, prec=0.550, f1=0.489, auc=0.583\n",
      "  Subject s10202: acc=0.667, prec=0.667, f1=0.667, auc=0.722\n",
      "Mean over subjects — acc=0.575, prec=0.579, f1=0.573, auc=0.607\n",
      "\n",
      "=== Model: mlp ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10014: acc=0.519, prec=0.533, f1=0.390, auc=0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10052: acc=0.500, prec=0.500, f1=0.286, auc=0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10059: acc=0.643, prec=0.750, f1=0.545, auc=0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10073: acc=0.714, prec=0.750, f1=0.692, auc=0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10081: acc=0.688, prec=0.846, f1=0.595, auc=0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10084: acc=0.619, prec=0.667, f1=0.556, auc=0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10085: acc=0.654, prec=0.750, f1=0.571, auc=0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10089: acc=0.636, prec=0.667, f1=0.600, auc=0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10094: acc=0.500, prec=0.500, f1=0.500, auc=0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10100: acc=0.548, prec=0.600, f1=0.391, auc=0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10103: acc=0.571, prec=0.545, f1=0.667, auc=0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10110: acc=0.531, prec=0.533, f1=0.516, auc=0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10111: acc=0.581, prec=0.561, f1=0.639, auc=0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10115: acc=0.589, prec=0.576, f1=0.623, auc=0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10117: acc=0.455, prec=0.444, f1=0.400, auc=0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10121: acc=0.571, prec=0.562, f1=0.600, auc=0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10125: acc=0.521, prec=0.511, f1=0.667, auc=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10138: acc=0.537, prec=0.562, f1=0.419, auc=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10139: acc=0.833, prec=0.800, f1=0.842, auc=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10141: acc=0.536, prec=0.571, f1=0.381, auc=0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10144: acc=0.786, prec=0.750, f1=0.800, auc=0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10145: acc=0.426, prec=0.400, f1=0.340, auc=0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10148: acc=0.529, prec=0.529, f1=0.529, auc=0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10153: acc=0.478, prec=0.467, f1=0.368, auc=0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10156: acc=0.758, prec=0.808, f1=0.737, auc=0.862\n",
      "  Subject s10158: acc=0.656, prec=0.614, f1=0.711, auc=0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10159: acc=0.550, prec=0.636, f1=0.341, auc=0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10160: acc=0.654, prec=0.643, f1=0.667, auc=0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10165: acc=0.474, prec=0.000, f1=0.000, auc=0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10173: acc=0.700, prec=1.000, f1=0.571, auc=0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10177: acc=0.575, prec=0.714, f1=0.370, auc=0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10178: acc=0.538, prec=0.556, f1=0.455, auc=0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10180: acc=0.677, prec=0.634, f1=0.722, auc=0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10181: acc=0.515, prec=0.511, f1=0.590, auc=0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10183: acc=0.500, prec=0.500, f1=0.667, auc=0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10185: acc=0.750, prec=0.667, f1=0.800, auc=0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10186: acc=0.769, prec=0.706, f1=0.800, auc=0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10188: acc=0.524, prec=0.516, f1=0.615, auc=0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10192: acc=0.606, prec=0.564, f1=0.705, auc=0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10195: acc=0.576, prec=0.568, f1=0.600, auc=0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10196: acc=0.900, prec=0.833, f1=0.909, auc=1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10197: acc=0.500, prec=0.500, f1=0.526, auc=0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10200: acc=0.600, prec=0.632, f1=0.545, auc=0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/pi/djangraw/hsun11/miniconda3/envs/roamm/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject s10202: acc=0.500, prec=0.500, f1=0.400, auc=0.611\n",
      "Mean over subjects — acc=0.597, prec=0.602, f1=0.560, auc=0.644\n",
      "\n",
      "Saved per-sample LOSO predictions to /gpfs1/pi/djangraw/mindless_reading/data/ml_results/loso_predictions_mw_fixed.csv\n",
      "\n",
      "Saved aggregated metrics to /gpfs1/pi/djangraw/mindless_reading/data/ml_results/loso_metrics_mw_fixed.csv\n",
      "\n",
      "=== Overall summary ===\n",
      "   feature_set              model  accuracy  precision        f1       auc  \\\n",
      "2          EEG         linear_svc  0.507711   0.507898  0.501801  0.504276   \n",
      "3          EEG             logreg  0.505338   0.505441  0.500599  0.503760   \n",
      "6          EEG            rbf_svc  0.505338   0.506089  0.472819  0.492686   \n",
      "5          EEG      random_forest  0.502966   0.502365  0.558947  0.513208   \n",
      "4          EEG                mlp  0.498221   0.498343  0.516018  0.501843   \n",
      "0          EEG  gradient_boosting  0.489917   0.490608  0.508009  0.486597   \n",
      "1          EEG                knn  0.482206   0.483184  0.496830  0.473006   \n",
      "9    EEG + Eye         linear_svc  0.580071   0.583026  0.572464  0.590092   \n",
      "10   EEG + Eye             logreg  0.576512   0.578563  0.570913  0.587961   \n",
      "13   EEG + Eye            rbf_svc  0.562871   0.562207  0.565192  0.594663   \n",
      "7    EEG + Eye  gradient_boosting  0.559312   0.555928  0.572251  0.573314   \n",
      "12   EEG + Eye      random_forest  0.555160   0.547988  0.586093  0.578743   \n",
      "11   EEG + Eye                mlp  0.537367   0.534351  0.556818  0.550041   \n",
      "8    EEG + Eye                knn  0.483986   0.483986  0.483986  0.479597   \n",
      "20         Eye            rbf_svc  0.607948   0.616368  0.593231  0.636031   \n",
      "17         Eye             logreg  0.603796   0.605549  0.600478  0.636662   \n",
      "16         Eye         linear_svc  0.602610   0.604091  0.599761  0.636781   \n",
      "18         Eye                mlp  0.586002   0.590062  0.576456  0.616241   \n",
      "14         Eye  gradient_boosting  0.576512   0.578372  0.571429  0.607123   \n",
      "19         Eye      random_forest  0.564650   0.565426  0.562053  0.605593   \n",
      "15         Eye                knn  0.564057   0.562212  0.570427  0.593637   \n",
      "\n",
      "    n_samples  \n",
      "2        1686  \n",
      "3        1686  \n",
      "6        1686  \n",
      "5        1686  \n",
      "4        1686  \n",
      "0        1686  \n",
      "1        1686  \n",
      "9        1686  \n",
      "10       1686  \n",
      "13       1686  \n",
      "7        1686  \n",
      "12       1686  \n",
      "11       1686  \n",
      "8        1686  \n",
      "20       1686  \n",
      "17       1686  \n",
      "16       1686  \n",
      "18       1686  \n",
      "14       1686  \n",
      "19       1686  \n",
      "15       1686  \n",
      "\n",
      "Saved subject-level metrics to /gpfs1/pi/djangraw/mindless_reading/data/ml_results/loso_subject_metrics_mw_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    ")\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ==========================\n",
    "# Config & data loading\n",
    "# ==========================\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "df = pd.read_csv(\n",
    "    os.path.join(data_root, f\"all_subjects_R_eeget_features_mw_fixed.csv\")\n",
    ")\n",
    "# get the feature columns for EEG and eye-tracking\n",
    "eye_features = [\n",
    " 'norm_fix_word_num',\n",
    " 'norm_in_word_reg',\n",
    " 'norm_out_word_reg',\n",
    " 'zipf_fixdur_corr',\n",
    " 'word_length_fixdur_corr',\n",
    " 'norm_total_viewing',\n",
    " 'fix_dispersion',\n",
    " 'weighted_vergence',\n",
    " 'norm_sacc_num',\n",
    " 'sacc_length',\n",
    " 'horizontal_sacc',\n",
    " 'pupil_slope',\n",
    " 'page_norm_pupil_mean']\n",
    "eye_idx = [df.columns.get_loc(feat) for feat in eye_features]\n",
    "\n",
    "band_names = [\n",
    "    \"theta1\", \"theta2\", \"alpha1\", \"alpha2\",\n",
    "    \"beta1\", \"beta2\", \"gamma1\", \"gamma2\",\n",
    "]\n",
    "eeg_idx = [i for i, col in enumerate(df.columns) if any(col.endswith(f\"_{band}\") for band in band_names)]\n",
    "\n",
    "X_eye = df.iloc[:, eye_idx].values\n",
    "X_eeg = df.iloc[:, eeg_idx].values\n",
    "X = np.hstack([X_eeg, X_eye])  # combined features\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"subject_id\"].values  # for LOSO\n",
    "\n",
    "# ==========================\n",
    "# Models\n",
    "# ==========================\n",
    "pca_variance = 0.95  # keep 95% variance; or set an int for n_components\n",
    "base_models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    \"linear_svc\": LinearSVC(),  # no probas, but we can use decision_function\n",
    "    \"rbf_svc\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"random_forest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"mlp\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# LOSO + prediction logging\n",
    "# ==========================\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "all_preds = []  # per-sample predictions across all folds / models / feature sets\n",
    "\n",
    "for feature_set, X_data in zip(\n",
    "    [\"EEG + Eye\", \"EEG\", \"Eye\"],\n",
    "    [X, X_eeg, X_eye],\n",
    "):\n",
    "    # drop naN features (if any) for this feature set\n",
    "    valid_cols = ~np.isnan(X_data).any(axis=0)\n",
    "    X_data = X_data[:, valid_cols]\n",
    "    \n",
    "    print(f\"\\n========== Feature set: {feature_set} ==========\")\n",
    "\n",
    "    for model_name, base_clf in base_models.items():\n",
    "        print(f\"\\n=== Model: {model_name} ===\")\n",
    "\n",
    "        acc_list = []\n",
    "        f1_list = []\n",
    "        prec_list = []\n",
    "        auc_list = []\n",
    "\n",
    "        for train_idx, test_idx in logo.split(X_data, y, groups=groups):\n",
    "            subj_test = np.unique(groups[test_idx])\n",
    "            assert len(subj_test) == 1  # LOSO: only one subject held out\n",
    "            subj_test = subj_test[0]\n",
    "\n",
    "            X_train, X_test = X_data[train_idx], X_data[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            # fresh clone of classifier\n",
    "            clf = clone(base_clf)\n",
    "\n",
    "            # Pipeline: StandardScaler -> PCA -> classifier\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"pca\", PCA(n_components=pca_variance)),\n",
    "                (\"clf\", clf),\n",
    "            ])\n",
    "\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_test)\n",
    "\n",
    "            # scores for AUC\n",
    "            y_scores = None\n",
    "            if hasattr(pipe, \"predict_proba\"):\n",
    "                try:\n",
    "                    y_scores = pipe.predict_proba(X_test)[:, 1]\n",
    "                except Exception:\n",
    "                    y_scores = None\n",
    "            elif hasattr(pipe, \"decision_function\"):\n",
    "                try:\n",
    "                    y_scores = pipe.decision_function(X_test)\n",
    "                except Exception:\n",
    "                    y_scores = None\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "            if (y_scores is not None) and (np.unique(y_test).size == 2):\n",
    "                auc = roc_auc_score(y_test, y_scores)\n",
    "            else:\n",
    "                auc = np.nan\n",
    "\n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "            prec_list.append(prec)\n",
    "            auc_list.append(auc)\n",
    "\n",
    "            # log per-subject fold summary\n",
    "            print(\n",
    "                f\"  Subject {subj_test}: \"\n",
    "                f\"acc={acc:.3f}, prec={prec:.3f}, f1={f1:.3f}, \"\n",
    "                f\"auc={auc if not np.isnan(auc) else float('nan'):.3f}\"\n",
    "            )\n",
    "\n",
    "            # store per-sample predictions for this fold\n",
    "            for i, idx in enumerate(test_idx):\n",
    "                all_preds.append({\n",
    "                    \"feature_set\": feature_set,\n",
    "                    \"model\": model_name,\n",
    "                    \"test_subject\": subj_test,\n",
    "                    \"sample_idx\": int(idx),\n",
    "                    \"y_true\": int(y_test[i]),\n",
    "                    \"y_pred\": int(y_pred[i]),\n",
    "                    \"y_score\": float(y_scores[i]) if y_scores is not None else np.nan,\n",
    "                })\n",
    "            \n",
    "            # break  # TEMP: only do one fold for testing; REMOVE for full LOSO\n",
    "\n",
    "        # per-model, per-feature-set mean over subjects\n",
    "        print(\n",
    "            f\"Mean over subjects — acc={np.mean(acc_list):.3f}, \"\n",
    "            f\"prec={np.mean(prec_list):.3f}, \"\n",
    "            f\"f1={np.mean(f1_list):.3f}, \"\n",
    "            f\"auc={np.nanmean(auc_list):.3f}\"\n",
    "        )\n",
    "\n",
    "# ==========================\n",
    "# Build DataFrame of predictions\n",
    "# ==========================\n",
    "df_preds = pd.DataFrame(all_preds)\n",
    "\n",
    "results_dir = os.path.join(data_root, \"ml_results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "pred_file = os.path.join(\n",
    "    results_dir,\n",
    "    f\"loso_predictions_mw_fixed.csv\",\n",
    ")\n",
    "df_preds.to_csv(pred_file, index=False)\n",
    "print(f\"\\nSaved per-sample LOSO predictions to {pred_file}\")\n",
    "\n",
    "# ==========================\n",
    "# Final metrics from saved predictions (overall)\n",
    "# ==========================\n",
    "rows = []\n",
    "for (feature_set, model_name), g in df_preds.groupby([\"feature_set\", \"model\"]):\n",
    "    y_true = g[\"y_true\"].values\n",
    "    y_pred = g[\"y_pred\"].values\n",
    "    y_score = g[\"y_score\"].values\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    # AUC over all samples for this (feature_set, model)\n",
    "    if np.unique(y_true).size == 2 and not np.all(np.isnan(y_score)):\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"feature_set\": feature_set,\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc,\n",
    "        \"n_samples\": len(g),\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "metrics_file = os.path.join(\n",
    "    results_dir,\n",
    "    f\"loso_metrics_mw_fixed.csv\",\n",
    ")\n",
    "df_metrics.to_csv(metrics_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved aggregated metrics to {metrics_file}\")\n",
    "print(\"\\n=== Overall summary ===\")\n",
    "print(df_metrics.sort_values([\"feature_set\", \"accuracy\"], ascending=[True, False]))\n",
    "\n",
    "# ==========================\n",
    "# Subject-level metrics\n",
    "# ==========================\n",
    "rows_subj = []\n",
    "for (feature_set, model_name, subj), g in df_preds.groupby(\n",
    "    [\"feature_set\", \"model\", \"test_subject\"]\n",
    "):\n",
    "    y_true = g[\"y_true\"].values\n",
    "    y_pred = g[\"y_pred\"].values\n",
    "    y_score = g[\"y_score\"].values\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    if np.unique(y_true).size == 2 and not np.all(np.isnan(y_score)):\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "    rows_subj.append({\n",
    "        \"feature_set\": feature_set,\n",
    "        \"model\": model_name,\n",
    "        \"subject_id\": subj,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc,\n",
    "        \"n_samples\": len(g),\n",
    "    })\n",
    "\n",
    "df_subject_metrics = pd.DataFrame(rows_subj)\n",
    "\n",
    "subj_metrics_file = os.path.join(\n",
    "    results_dir,\n",
    "    f\"loso_subject_metrics_mw_fixed.csv\",\n",
    ")\n",
    "df_subject_metrics.to_csv(subj_metrics_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved subject-level metrics to {subj_metrics_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roamm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
