{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1bd4e4",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf63c2",
   "metadata": {},
   "source": [
    "## Individual process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f88933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10014...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s10014 runs:   0%|          | 0/5 [00:00<?, ?run/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10052...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10059...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10073...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10081...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10084...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10085...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10089...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10094...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10103...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10110...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10111...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10115...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10117...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10121...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10138...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10139...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10141...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10144...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10145...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10148...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10153...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10158...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10159...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10160...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10165...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10173...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10177...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10178...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10180...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10181...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10183...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10185...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10186...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10188...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10192...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10195...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10196...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10197...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10200...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject s10202...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, sosfiltfilt, hilbert\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def fixation_bandpower_hilbert(df_page):\n",
    "    \"\"\"\n",
    "    Compute fixation-aligned EEG bandpower features using:\n",
    "      1) Band-pass filter per frequency band (SciPy butter + sosfiltfilt)\n",
    "      2) Hilbert transform to obtain analytic signal\n",
    "      3) Instantaneous bandpower time series = |analytic|^2 (log10 transformed)\n",
    "      4) Aggregate bandpower within each fixation window using sample indices\n",
    "\n",
    "    Expected input `df_page`:\n",
    "      - Rows are time samples, ordered in time)\n",
    "      - First 64 columns are EEG channel values (continuous EEG samples)\n",
    "      - Columns include:\n",
    "          sfreq (constant per run/page is fine),\n",
    "          fix_R_tStart, fix_R_tEnd,\n",
    "          is_mw,\n",
    "          fix_R_fixed_word, fix_R_fixed_word_key,\n",
    "          sentence_id, sentence\n",
    "\n",
    "    Returns:\n",
    "      DataFrame with one row per fixation interval and columns:\n",
    "        {ch}_{band} for 64*8 features + metadata cols.\n",
    "    \"\"\"\n",
    "\n",
    "    bands = {\n",
    "        \"theta1\": (4.0, 6.0),\n",
    "        \"theta2\": (6.5, 8.0),\n",
    "        \"alpha1\": (8.5, 10.0),\n",
    "        \"alpha2\": (10.5, 13.0),\n",
    "        \"beta1\":  (13.5, 18.0),\n",
    "        \"beta2\":  (18.5, 30.0),\n",
    "        \"gamma1\": (30.5, 40.0),\n",
    "        \"gamma2\": (40.0, 49.5),\n",
    "    }\n",
    "\n",
    "    # ---------------------------\n",
    "    # EEG: (n_ch, n_times)\n",
    "    # ---------------------------\n",
    "    eeg = df_page.iloc[:, :64].to_numpy(dtype=np.float64).T\n",
    "    n_ch, n_times = eeg.shape\n",
    "\n",
    "    ch_names = df_page.columns.values[:64].tolist()\n",
    "    sfreq = float(df_page[\"sfreq\"].iloc[0])\n",
    "    nyq = sfreq / 2.0\n",
    "\n",
    "    # ---------------------------\n",
    "    # Build fixation index table: one row per fixation interval\n",
    "    # start_idx/end_idx are *sample indices* (row indices) within df_page\n",
    "    # ---------------------------\n",
    "    df_fix_idx = (\n",
    "        df_page.dropna(subset=[\n",
    "            \"fix_R_tStart\", \"fix_R_tEnd\",\n",
    "            \"is_mw\", \"fix_R_fixed_word\", \"fix_R_fixed_word_key\",\n",
    "            \"sentence_id\", \"sentence\",\n",
    "        ])\n",
    "        .reset_index()  # creates column \"index\" = original sample row index\n",
    "        .groupby([\"fix_R_tStart\", \"fix_R_tEnd\"], as_index=False)\n",
    "        .agg(\n",
    "            start_idx=(\"index\", \"min\"),\n",
    "            end_idx=(\"index\", \"max\"),\n",
    "            is_mw=(\"is_mw\", \"mean\"),\n",
    "            fix_R_fixed_word=(\"fix_R_fixed_word\", \"first\"),\n",
    "            fix_R_fixed_word_key=(\"fix_R_fixed_word_key\", \"first\"),\n",
    "            sentence_id=(\"sentence_id\", \"first\"),\n",
    "            sentence=(\"sentence\", \"first\"),\n",
    "        )\n",
    "        .sort_values([\"fix_R_tStart\", \"fix_R_tEnd\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if df_fix_idx.empty:\n",
    "        # no fixations found on this page\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    start_samp = np.clip(df_fix_idx[\"start_idx\"].to_numpy(), 0, n_times - 1)\n",
    "    end_samp   = np.clip(df_fix_idx[\"end_idx\"].to_numpy(),   0, n_times - 1)\n",
    "\n",
    "    band_names = list(bands.keys())\n",
    "    band_ranges = [bands[b] for b in band_names]\n",
    "    n_fix = len(df_fix_idx)\n",
    "    n_bands = len(band_names)\n",
    "\n",
    "    feat = np.full((n_fix, n_ch, n_bands), np.nan, dtype=np.float64)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Filter + Hilbert per band, then aggregate per fixation\n",
    "    # ---------------------------\n",
    "    for bi, (fmin, fmax) in enumerate(band_ranges):\n",
    "        # SciPy band-pass (zero-phase)\n",
    "        sos = butter(\n",
    "            N=4,\n",
    "            Wn=[fmin / nyq, fmax / nyq],\n",
    "            btype=\"bandpass\",\n",
    "            output=\"sos\",\n",
    "        )\n",
    "        x_filt = sosfiltfilt(sos, eeg, axis=1)           # filter over time\n",
    "        x_analytic = hilbert(x_filt, axis=1)             # hilbert over time\n",
    "        power = np.abs(x_analytic) ** 2                  # (n_ch, n_times)\n",
    "        # power = np.log10(power + 1e-20)                  # log power\n",
    "\n",
    "        for i in range(n_fix):\n",
    "            s = int(start_samp[i])\n",
    "            e = int(end_samp[i])\n",
    "            if e < s:\n",
    "                continue\n",
    "            feat[i, :, bi] = np.nanmean(power[:, s:e+1], axis=1)\n",
    "\n",
    "    # Flatten features: (n_fix, n_ch*n_bands)\n",
    "    feat_flat = feat.reshape(n_fix, n_ch * n_bands)\n",
    "    columns = [f\"{ch}_{band}\" for ch in ch_names for band in band_names]\n",
    "    df_psd = pd.DataFrame(feat_flat, columns=columns)\n",
    "\n",
    "    # Attach fixation metadata\n",
    "    df_psd = pd.concat([df_psd, df_fix_idx[[\n",
    "        \"is_mw\",\n",
    "        \"fix_R_fixed_word\",\n",
    "        \"fix_R_fixed_word_key\",\n",
    "        \"sentence_id\",\n",
    "        \"sentence\",\n",
    "    ]].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return df_psd\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Main processing\n",
    "# ==========================\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "coords_root = \"/gpfs1/pi/djangraw/hsun11/roamm_ml/res\"\n",
    "\n",
    "all_subjects = sorted(\n",
    "    d for d in os.listdir(data_root)\n",
    "    if d.startswith(\"s\") and os.path.isdir(os.path.join(data_root, d))\n",
    ")\n",
    "\n",
    "for subject_id in all_subjects:\n",
    "    print(f\"Processing subject {subject_id}...\")\n",
    "    ml_data_dir = os.path.join(data_root, subject_id, \"ml_data\")\n",
    "    save_dir = os.path.join(ml_data_dir, \"eeg2text_data\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    pkl_files = sorted([f for f in os.listdir(ml_data_dir) if f.endswith(\".pkl\")])\n",
    "\n",
    "    # make sure each subject has 5 runs of data\n",
    "    if len(pkl_files) != 5:\n",
    "        raise ValueError(f\"Subject {subject_id} has {len(pkl_files)} runs instead of 5\")\n",
    "\n",
    "    subject_rows = []  # collect per-page fixation-level dfs, concat once\n",
    "\n",
    "    for pkl_file in tqdm(pkl_files, desc=f\"{subject_id} runs\", unit=\"run\", leave=False):\n",
    "        df = pd.read_pickle(os.path.join(ml_data_dir, pkl_file))\n",
    "\n",
    "        # Filter: first pass reading only\n",
    "        if \"first_pass_reading\" in df.columns:\n",
    "            df = df[df[\"first_pass_reading\"] == 1].copy()\n",
    "\n",
    "        # convert bool col explicitly to avoid pandas warning\n",
    "        for col in ['is_blink', 'is_sacc', 'is_fix', 'is_mw', 'first_pass_reading']:\n",
    "            df[col] = df[col] == True\n",
    "\n",
    "        # Filter out samples 2 seconds before page end\n",
    "        if \"time\" in df.columns and \"page_end\" in df.columns:\n",
    "            df = df[df[\"time\"] < (df[\"page_end\"] - 2)].copy()\n",
    "\n",
    "        df[\"subject_id\"] = subject_id\n",
    "\n",
    "        # Sentence info merge (word_key)\n",
    "        story_name = df[\"story_name\"].iloc[0]\n",
    "        coord_path = os.path.join(coords_root, f\"{story_name}_coordinates.csv\")\n",
    "        df_coords = pd.read_csv(coord_path)\n",
    "\n",
    "        df = df.merge(\n",
    "            df_coords[[\"sentence_id\", \"sentence\", \"word_key\"]],\n",
    "            left_on=\"fix_R_fixed_word_key\",\n",
    "            right_on=\"word_key\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Process each page\n",
    "        pages = sorted(df[\"page_num\"].unique().tolist())\n",
    "        for page in pages:\n",
    "            df_page = df[df[\"page_num\"] == page].copy()\n",
    "            df_fix_eeg = fixation_bandpower_hilbert(df_page)\n",
    "            if df_fix_eeg.empty:\n",
    "                continue\n",
    "            # Add metadata columns\n",
    "            df_fix_eeg[\"page_num\"] = page\n",
    "            df_fix_eeg[\"story_name\"] = story_name\n",
    "            df_fix_eeg[\"subject_id\"] = subject_id\n",
    "            subject_rows.append(df_fix_eeg)\n",
    "\n",
    "    if len(subject_rows) == 0:\n",
    "        Warning(f\"No fixation data found for subject {subject_id}, saving empty file.\")\n",
    "\n",
    "    df_group = pd.concat(subject_rows, ignore_index=True)\n",
    "    out_path = os.path.join(save_dir, f\"{subject_id}_eeg2text_data.csv\")\n",
    "    df_group.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effe62c",
   "metadata": {},
   "source": [
    "## Merge subject files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e17d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged dataset to:\n",
      "  /gpfs1/pi/djangraw/mindless_reading/data/all_subjects_eeg2text_data.csv\n",
      "Total rows: 394,319\n",
      "Total subjects loaded: 44\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_root = \"/gpfs1/pi/djangraw/mindless_reading/data\"\n",
    "all_subjects = sorted(\n",
    "    d for d in os.listdir(data_root)\n",
    "    if d.startswith(\"s\") and os.path.isdir(os.path.join(data_root, d))\n",
    ")\n",
    "df_list = []\n",
    "\n",
    "for subject_id in all_subjects:\n",
    "    ml_data_dir = os.path.join(data_root, subject_id, \"ml_data\")\n",
    "    save_dir = os.path.join(ml_data_dir, \"eeg2text_data\")\n",
    "    infile = os.path.join(save_dir, f\"{subject_id}_eeg2text_data.csv\")\n",
    "\n",
    "    df = pd.read_csv(infile)\n",
    "\n",
    "    df[\"subject_id\"] = subject_id  # enforce subject_id is correct\n",
    "    df_list.append(df)\n",
    "\n",
    "if len(df_list) == 0:\n",
    "    raise RuntimeError(\"No subject EEG2Text files were loaded. Nothing to concatenate.\")\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "out_file = os.path.join(data_root, \"all_subjects_eeg2text_data.csv\")\n",
    "df_all.to_csv(out_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved merged dataset to:\\n  {out_file}\")\n",
    "print(f\"Total rows: {len(df_all):,}\")\n",
    "print(f\"Total subjects loaded: {df_all['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99913156",
   "metadata": {},
   "source": [
    "# Examine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8c9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "seed = 42\n",
    "\n",
    "df = pd.read_csv(\"/gpfs1/pi/djangraw/mindless_reading/data/all_subjects_eeg2text_data.csv\")\n",
    "data_type = \"all\"  # options: \"all\", \"nr\", \"mw\"\n",
    "sentence_id_col = \"sentence_id\"\n",
    "sentence_col = \"sentence\"\n",
    "fix_key_col = \"fix_R_fixed_word_key\"\n",
    "assert data_type in {\"all\", \"nr\", \"mw\"}, f\"Invalid data_type={data_type}\"\n",
    "\n",
    "if data_type != \"all\":\n",
    "    if \"is_mw\" not in df.columns:\n",
    "        raise ValueError(\"Column 'is_mw' not found in CSV but data_type != 'all' was requested.\")\n",
    "    if data_type == \"nr\":\n",
    "        df = df[df[\"is_mw\"] == 0].reset_index(drop=True)\n",
    "    elif data_type == \"mw\":\n",
    "        df = df[df[\"is_mw\"] != 0].reset_index(drop=True)\n",
    "\n",
    "# Identify EEG feature columns: numeric columns excluding obvious metadata/labels.\n",
    "meta_cols = {\n",
    "    sentence_id_col, sentence_col, fix_key_col,\n",
    "    \"fix_R_fixed_word\", \"is_mw\", \"page_num\", \"story_name\", \"subject_id\",\n",
    "}\n",
    "eeg_cols = [c for c in df.columns if c not in meta_cols]\n",
    "eeg_cols = [c for c in eeg_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "if len(eeg_cols) == 0:\n",
    "    raise ValueError(\"No numeric EEG feature columns found after excluding metadata columns.\")\n",
    "eeg_cols = eeg_cols\n",
    "\n",
    "# Drop whole sentences containing any NaN in EEG features or missing sentence text\n",
    "# if drop_nan_sentences:\n",
    "#     good_ids = []\n",
    "#     for sid, g in df.groupby(sentence_id_col, sort=False):\n",
    "#         if g[self.sentence_col].isna().any():\n",
    "#             continue\n",
    "#         if g[self.eeg_cols].isna().any().any():\n",
    "#             continue\n",
    "#         good_ids.append(sid)\n",
    "#     df = df[df[sentence_id_col].isin(good_ids)].reset_index(drop=True)\n",
    "\n",
    "# Split by unique sentence text (unseen sentences in test)\n",
    "sent_ids = df[sentence_col].dropna().unique().tolist()\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(sent_ids)\n",
    "\n",
    "n = len(sent_ids)\n",
    "n_train = int(round(0.8 * n))\n",
    "n_dev = int(round(0.1 * n))\n",
    "\n",
    "train_ids = set(sent_ids[:n_train])\n",
    "dev_ids   = set(sent_ids[n_train:n_train + n_dev])\n",
    "test_ids  = set(sent_ids[n_train + n_dev:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roamm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
