{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject s10014 has been loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# define data root\n",
    "# this is the path to the ROAMM folder on local machine\n",
    "roamm_root = r\"/Users/hsun11/Documents/GlassBrainLab/MindlessReading/ROAMM\"\n",
    "ml_data_root = os.path.join(roamm_root, 'subject_ml_data')\n",
    "\n",
    "# =================================================================\n",
    "# load a single run of ml data\n",
    "subject_id = 's10014'\n",
    "subject_dir = os.path.join(ml_data_root, subject_id)\n",
    "run_number = 1\n",
    "df_sub_single_run = pd.read_pickle(os.path.join(subject_dir, f'{subject_id}_run{run_number}_ml_data.pkl'))\n",
    "\n",
    "# =================================================================\n",
    "# load all runs for a subject\n",
    "pkl_files = [f for f in os.listdir(subject_dir) if f.endswith('.pkl')]\n",
    "df_sub_all_runs = pd.DataFrame()\n",
    "for pkl_file in pkl_files:\n",
    "    df_sub_single_run = pd.read_pickle(os.path.join(subject_dir, pkl_file))\n",
    "    df_sub_all_runs = pd.concat([df_sub_all_runs, df_sub_single_run])\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# load all runs for all subjects\n",
    "all_subjects = [d for d in os.listdir(ml_data_root) if d.startswith('s') and os.path.isdir(os.path.join(ml_data_root, d))]\n",
    "df = pd.DataFrame()\n",
    "for subject_id in all_subjects:\n",
    "    subject_dir = os.path.join(ml_data_root, subject_id)\n",
    "    pkl_files = [f for f in os.listdir(subject_dir) if f.endswith('.pkl')]\n",
    "\n",
    "    # make sure each subject has 5 runs of data\n",
    "    if len(pkl_files) != 5:\n",
    "        raise ValueError(f\"Subject {subject_id} has {len(pkl_files)} runs instead of 5\")\n",
    "    \n",
    "    for pkl_file in pkl_files:\n",
    "        df_sub_single_run = pd.read_pickle(os.path.join(subject_dir, pkl_file))\n",
    "        # I highly recommend you to filter out reading runs that are not the first pass reading\n",
    "        # to save memory\n",
    "        df_sub_single_run = df_sub_single_run[df_sub_single_run['first_pass_reading'] == 1]\n",
    "        # add subject id to the dataframe   \n",
    "        df_sub_single_run['subject_id'] = subject_id\n",
    "        # convert bool col explicitly to avoid pandas warning\n",
    "        for col in ['is_blink', 'is_saccade', 'is_fixation', 'is_mw', 'first_pass_reading']:\n",
    "            df_sub_single_run[col] = df_sub_single_run[col] == True\n",
    "        # append to the dataframe\n",
    "        df = pd.concat([df, df_sub_single_run])\n",
    "    \n",
    "    print(f'Subject {subject_id} has been loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# define data root\n",
    "# this is the path to the ROAMM folder on local machine\n",
    "roamm_root = r\"/Users/hsun11/Documents/GlassBrainLab/MindlessReading/ROAMM\"\n",
    "ml_data_root = os.path.join(roamm_root, 'subject_ml_data')\n",
    "# define subject id\n",
    "subject_id = 's10014'\n",
    "subject_dir = os.path.join(ml_data_root, subject_id)\n",
    "# load all runs for a subject\n",
    "pkl_files = [f for f in os.listdir(subject_dir) if f.endswith('.pkl')]\n",
    "df = pd.DataFrame()\n",
    "for pkl_file in pkl_files:\n",
    "    df_sub_single_run = pd.read_pickle(os.path.join(subject_dir, pkl_file))\n",
    "    df_sub_single_run = df_sub_single_run[df_sub_single_run['first_pass_reading'] == 1]\n",
    "    # convert bool col explicitly to avoid pandas warning\n",
    "    for col in ['is_blink', 'is_saccade', 'is_fixation', 'is_mw', 'first_pass_reading']:\n",
    "        df_sub_single_run[col] = df_sub_single_run[col] == True\n",
    "    df = pd.concat([df, df_sub_single_run])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling data using 1-second windows (256 samples)...\n",
      "Original data size: 438227\n",
      "Downsampled data size: 6771\n",
      "Data downsampling completed.\n",
      "Handling class imbalance...\n",
      "Class distribution:\n",
      "0.0    1386\n",
      "1.0    1386\n",
      "Name: is_mw, dtype: int64\n",
      "\n",
      "==================================================\n",
      "=== EEG Features Only ===\n",
      "==================================================\n",
      "EEG-only Accuracy: 0.831\n",
      "\n",
      "EEG-only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83       278\n",
      "         1.0       0.82      0.84      0.83       277\n",
      "\n",
      "    accuracy                           0.83       555\n",
      "   macro avg       0.83      0.83      0.83       555\n",
      "weighted avg       0.83      0.83      0.83       555\n",
      "\n",
      "\n",
      "EEG-only Confusion Matrix:\n",
      "[[227  51]\n",
      " [ 43 234]]\n",
      "\n",
      "==================================================\n",
      "=== Eye Tracking Features Only ===\n",
      "==================================================\n",
      "Eye-only Accuracy: 0.805\n",
      "\n",
      "Eye-only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.81       278\n",
      "         1.0       0.81      0.80      0.80       277\n",
      "\n",
      "    accuracy                           0.81       555\n",
      "   macro avg       0.81      0.81      0.81       555\n",
      "weighted avg       0.81      0.81      0.81       555\n",
      "\n",
      "\n",
      "Eye-only Confusion Matrix:\n",
      "[[225  53]\n",
      " [ 55 222]]\n",
      "\n",
      "==================================================\n",
      "=== Combined EEG + Eye Tracking Features ===\n",
      "==================================================\n",
      "Combined Accuracy: 0.877\n",
      "\n",
      "Combined Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.86      0.88       278\n",
      "         1.0       0.87      0.89      0.88       277\n",
      "\n",
      "    accuracy                           0.88       555\n",
      "   macro avg       0.88      0.88      0.88       555\n",
      "weighted avg       0.88      0.88      0.88       555\n",
      "\n",
      "\n",
      "Combined Confusion Matrix:\n",
      "[[240  38]\n",
      " [ 30 247]]\n",
      "\n",
      "==================================================\n",
      "=== PERFORMANCE SUMMARY ===\n",
      "==================================================\n",
      "EEG-only Accuracy:      0.831\n",
      "Eye-only Accuracy:      0.805\n",
      "Combined Accuracy:      0.877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Prepare features and target\n",
    "# Select EEG and eye tracking features\n",
    "eeg_cols = df.columns.tolist()[:64]  #first 64 columns are EEG channels\n",
    "eye_cols = ['blink_interp_LX', 'blink_interp_LY', 'blink_interp_RX', 'blink_interp_RY','blink_interp_LPupil', 'blink_interp_RPupil']\n",
    "\n",
    "\n",
    "# Downsample data using 1-second windows (fs = 256 Hz)\n",
    "def downsample_data(df, window_size=64):\n",
    "    \"\"\"Downsample data using 1-second windows\"\"\"\n",
    "    downsampled_data = []\n",
    "    \n",
    "    # Process data in chunks of window_size\n",
    "    for i in range(0, len(df), window_size):\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        \n",
    "        # Skip if window is too small\n",
    "        if len(window) < window_size:\n",
    "            continue\n",
    "            \n",
    "        # Check if labels are consistent in this window\n",
    "        labels_in_window = window['is_mw'].unique()\n",
    "        if len(labels_in_window) > 1:\n",
    "            # Skip windows with mixed labels\n",
    "            continue\n",
    "            \n",
    "        # Calculate mean for feature columns\n",
    "        window_data = {}\n",
    "        for col in eeg_cols + eye_cols:\n",
    "            window_data[col] = window[col].mean()\n",
    "            \n",
    "        # Use the consistent label\n",
    "        window_data['is_mw'] = labels_in_window[0]\n",
    "    \n",
    "                \n",
    "        downsampled_data.append(window_data)\n",
    "    \n",
    "    return pd.DataFrame(downsampled_data)\n",
    "\n",
    "print(\"Downsampling data using 1-second windows (256 samples)...\")\n",
    "print(f\"Original data size: {len(df)}\")\n",
    "df_downsampled = downsample_data(df)\n",
    "print(f\"Downsampled data size: {len(df_downsampled)}\")\n",
    "print(\"Data downsampling completed.\")\n",
    "\n",
    "# Handle class imbalance\n",
    "print(\"Handling class imbalance...\")\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(df_downsampled[eeg_cols + eye_cols], df_downsampled['is_mw'])\n",
    "print(f\"Class distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# First, let's try EEG features only\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== EEG Features Only ===\")\n",
    "print(\"=\"*50)\n",
    "X_eeg = X_resampled[eeg_cols].copy()\n",
    "y_eeg = y_resampled\n",
    "\n",
    "# Split the data\n",
    "X_eeg_train, X_eeg_test, y_eeg_train, y_eeg_test = train_test_split(\n",
    "    X_eeg, y_eeg, test_size=0.2, random_state=42, stratify=y_eeg\n",
    ")\n",
    "\n",
    "# Create pipeline with scaling and classifier\n",
    "eeg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train and evaluate EEG-only model\n",
    "eeg_pipeline.fit(X_eeg_train, y_eeg_train)\n",
    "y_eeg_pred = eeg_pipeline.predict(X_eeg_test)\n",
    "\n",
    "print(f\"EEG-only Accuracy: {accuracy_score(y_eeg_test, y_eeg_pred):.3f}\")\n",
    "print(\"\\nEEG-only Classification Report:\")\n",
    "print(classification_report(y_eeg_test, y_eeg_pred))\n",
    "print(\"\\nEEG-only Confusion Matrix:\")\n",
    "print(confusion_matrix(y_eeg_test, y_eeg_pred))\n",
    "\n",
    "# Next, let's try eye tracking features only\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Eye Tracking Features Only ===\")\n",
    "print(\"=\"*50)\n",
    "X_eye = X_resampled[eye_cols].copy()\n",
    "y_eye = y_resampled\n",
    "\n",
    "# Split the data\n",
    "X_eye_train, X_eye_test, y_eye_train, y_eye_test = train_test_split(\n",
    "    X_eye, y_eye, test_size=0.2, random_state=42, stratify=y_eye\n",
    ")\n",
    "\n",
    "# Create pipeline with scaling and classifier\n",
    "eye_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train and evaluate eye-only model\n",
    "eye_pipeline.fit(X_eye_train, y_eye_train)\n",
    "y_eye_pred = eye_pipeline.predict(X_eye_test)\n",
    "\n",
    "print(f\"Eye-only Accuracy: {accuracy_score(y_eye_test, y_eye_pred):.3f}\")\n",
    "print(\"\\nEye-only Classification Report:\")\n",
    "print(classification_report(y_eye_test, y_eye_pred))\n",
    "print(\"\\nEye-only Confusion Matrix:\")\n",
    "print(confusion_matrix(y_eye_test, y_eye_pred))\n",
    "\n",
    "# Now let's try combined features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Combined EEG + Eye Tracking Features ===\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Create pipeline with scaling and classifier\n",
    "combined_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train and evaluate combined model\n",
    "combined_pipeline.fit(X_train, y_train)\n",
    "y_pred = combined_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Combined Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nCombined Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCombined Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== PERFORMANCE SUMMARY ===\")\n",
    "print(\"=\"*50)\n",
    "print(f\"EEG-only Accuracy:      {accuracy_score(y_eeg_test, y_eeg_pred):.3f}\")\n",
    "print(f\"Eye-only Accuracy:      {accuracy_score(y_eye_test, y_eye_pred):.3f}\")\n",
    "print(f\"Combined Accuracy:      {accuracy_score(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Comparison\n",
    "\n",
    "This section implements and evaluates all the models from the research comparison, including:\n",
    "- Traditional ML: KNN, GaussianNB, LinearSVC, RBF SVC/SVR, Linear/Ridge/Lasso/Elastic Net Regression\n",
    "- Ensemble Methods: Random Forest, Gradient Boost, AdaBoost, XGBoost\n",
    "- Deep Learning: CNN, PyramidalCNN, EEGNet, InceptionTime, Xception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iclr26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
